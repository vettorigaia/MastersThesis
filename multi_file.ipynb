{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191aabc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#da fare:\n",
    "#sistemare report\n",
    "#sistemare clustering\n",
    "#classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c6d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NewLibraryENGcopia import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f240e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "list_dir=glob.glob(\"/Users/Gaia_1/Desktop/allh5files/*.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5800ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from NewLibraryENGcopia import *\n",
    "import glob\n",
    "final=[]\n",
    "list_dir=glob.glob(\"/Users/Gaia_1/Desktop/allh5filesprova2/*\")\n",
    "for file in list_dir:\n",
    "    target=1\n",
    "    stim=0\n",
    "    if 'healthy' in file:\n",
    "        target=0\n",
    "        print('healthy')\n",
    "    if 'stimulation' in file:\n",
    "        stim=1\n",
    "        print('baseline')\n",
    "    file_name = file.split(\"/\")[-1]\n",
    "    print(file_name,':','target',target,'stimulation',stim)\n",
    "    neurons=spike_sorting(file_name,file,1,5,1.5)\n",
    "    df=poiproc(neurons,target,stim)\n",
    "    final.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cc51dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_dataframes = [elem.T for elem in tqdm(final)]\n",
    "final_result = pd.concat(concatenated_dataframes, axis=0)\n",
    "dataset=final_result\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c4c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4accfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score\n",
    "X = dataset.drop(['Target','Stimulation'],axis=1)\n",
    "y= dataset['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.25,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922c1bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be18e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af57cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5,svd_solver='full')\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(pca.fit(X_train).explained_variance_ratio_,sum(pca.fit(X_train).explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238c25f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth':np.linspace(2,10,dtype='int'),'criterion':['gini','entropy']}\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=12)\n",
    "\n",
    "gs = GridSearchCV(clf, params, scoring='roc_auc',cv=cv,n_jobs=-1)\n",
    "\n",
    "gs=gs.fit(X_train,y_train)\n",
    "\n",
    "gs_pca = GridSearchCV(clf, params, scoring='roc_auc',cv=cv,n_jobs=-1)\n",
    "gs_pca = gs_pca.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4fa137",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found :\",gs.best_params_,'\\n')\n",
    "print(\"Classification report on Test set\\n\")\n",
    "\n",
    "y_true, y_pred = y_test, gs.predict(X_test)\n",
    "\n",
    "accuracy = round(accuracy_score(y_true, y_pred),3)\n",
    "recall = round(recall_score(y_true, y_pred),3)\n",
    "precision = round(precision_score(y_true, y_pred),3)\n",
    "roc_auc = round(roc_auc_score(y_true, y_pred),3)\n",
    "\n",
    "print('Accuracy: ',accuracy)\n",
    "print('Recall: ',recall)\n",
    "print('Precision: ',precision)\n",
    "print('ROC AUC: ',roc_auc)\n",
    "print('\\n\\n Result with PCA\\n')\n",
    "print(\"Best parameters set found :\",gs_pca.best_params_,'\\n')\n",
    "print(\"Classification report on Test set\\n\")\n",
    "\n",
    "y_true, y_pred = y_test, gs_pca.predict(X_test_pca)\n",
    "\n",
    "accuracy = round(accuracy_score(y_true, y_pred),3)\n",
    "recall = round(recall_score(y_true, y_pred),3)\n",
    "precision = round(precision_score(y_true, y_pred),3)\n",
    "roc_auc = round(roc_auc_score(y_true, y_pred),3)\n",
    "\n",
    "print('Accuracy: ',accuracy)\n",
    "print('Recall: ',recall)\n",
    "print('Precision: ',precision)\n",
    "print('ROC AUC: ',roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f9e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab0407",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators':np.linspace(10,150,dtype='int',num=10),'max_depth':np.linspace(2,5,dtype='int'),'criterion':['gini','entropy']}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1,random_state=12)\n",
    "\n",
    "gs = GridSearchCV(clf, params, scoring='roc_auc',cv=cv,verbose=10,n_jobs=-1)\n",
    "\n",
    "gs=gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a28e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found :\",gs.best_params_,'\\n')\n",
    "print(\"Classification report on Test set\\n\")\n",
    "\n",
    "y_true, y_pred = y_test, gs.predict(X_test)\n",
    "\n",
    "accuracy = round(accuracy_score(y_true, y_pred),3)\n",
    "recall = round(recall_score(y_true, y_pred),3)\n",
    "precision = round(precision_score(y_true, y_pred),3)\n",
    "roc_auc = round(roc_auc_score(y_true, y_pred),3)\n",
    "\n",
    "print('Accuracy: ',accuracy)\n",
    "print('Recall: ',recall)\n",
    "print('Precision: ',precision)\n",
    "print('ROC AUC: ',roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e688ccf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2915c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fac4480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe4ceb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 10000 #Sampling Frequency\n",
    "all_data=[]\n",
    "all_ref=[]\n",
    "for file in tqdm(list_dir):\n",
    "    string=file\n",
    "    data=h5py.File(string,'r')\n",
    "    data_readings = data['Data']['Recording_0']['AnalogStream']['Stream_0']['ChannelData'][()]\n",
    "    info = data['Data']['Recording_0']['AnalogStream']['Stream_0']['InfoChannel'][()]\n",
    "    info_table = pd.DataFrame(info, columns = list(info.dtype.fields.keys()))\n",
    "    labels = info_table['Label']\n",
    "    readings = pd.DataFrame(data = data_readings.transpose(), columns = labels)\n",
    "    ref=readings[b'Ref']\n",
    "    len_data=len(readings)\n",
    "    readings=readings.drop([b'Ref'],axis=1)\n",
    "    #readings=readings.iloc[0:len_data, 17:23]\n",
    "    ref=ref[0:len_data]\n",
    "    all_ref.append(ref)\n",
    "    print(file,readings.shape)\n",
    "    all_data.append(readings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2dfdb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b784f21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lowcut = 300\n",
    "highcut = 3000\n",
    "fs=10000\n",
    "order=8\n",
    "b,a=butter_bandpass(lowcut,highcut,fs,order=order)\n",
    "filtered_all_data=[]\n",
    "for file in tqdm(range(len(all_data))):\n",
    "    prova=all_data[file]\n",
    "    ref=all_ref[file]\n",
    "    prova_rows = range(prova.shape[0])\n",
    "    filt_prova = pd.DataFrame(data = 0, columns=prova.columns, index=prova_rows, dtype = \"float32\")\n",
    "    filt_ref=filtfilt(b,a,ref)\n",
    "    for x in tqdm(range(prova.shape[1])):\n",
    "        filt_prova.values[:,x] = scipy.signal.filtfilt(b, a, prova.values[:,x])\n",
    "    for electrode in prova.columns:\n",
    "        filt_prova[electrode] = filt_prova[electrode] - filt_ref\n",
    "    filtered_all_data.append(filt_prova)\n",
    "    filt_prova.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3320c0",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94070a97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_ind=[]\n",
    "neg_ind=[]\n",
    "for file in tqdm(range(len(filtered_all_data))):\n",
    "    pos_ind_file=[]\n",
    "    neg_ind_file=[]\n",
    "    prova=filtered_all_data[file]\n",
    "    for electrode in tqdm(prova.columns):\n",
    "        channel=prova[electrode]\n",
    "        pos, neg=find_all_spikes(channel)\n",
    "        pos_ind_file.append(pos)\n",
    "        neg_ind_file.append(neg)\n",
    "    pos_ind.append(pos_ind_file)\n",
    "    neg_ind.append(neg_ind_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3502cf",
   "metadata": {},
   "source": [
    "# Cutouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7644f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_cut=[]\n",
    "neg_cut=[]\n",
    "n_pos=[]\n",
    "n_neg=[]\n",
    "for file in tqdm(range(len(filtered_all_data))):\n",
    "    pos_cut_file=[]\n",
    "    neg_cut_file=[]\n",
    "    n_pos_file=[]\n",
    "    n_neg_file=[]\n",
    "    prova=filtered_all_data[file]\n",
    "    pos_ind_file=pos_ind[file]\n",
    "    neg_ind_file=neg_ind[file]\n",
    "    for i,electrode in enumerate(tqdm(prova.columns)):\n",
    "        pos=pos_ind_file[i]\n",
    "        neg=neg_ind_file[i]\n",
    "        channel=prova[electrode]\n",
    "        pos_cut1,n_pos1, neg_cut1,n_neg1 = cut(pos,neg,channel)\n",
    "        pos_cut_file.append(pos_cut1)\n",
    "        neg_cut_file.append(neg_cut1)\n",
    "        n_pos_file.append(n_pos1)\n",
    "        n_neg_file.append(n_neg1)\n",
    "    pos_cut.append(pos_cut_file)\n",
    "    neg_cut.append(neg_cut_file)\n",
    "    n_pos.append(n_pos_file)\n",
    "    n_neg.append(n_neg_file)\n",
    "#savedp = copy.deepcopy(pos_cut)\n",
    "#savedn = copy.deepcopy(neg_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c939347d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in tqdm(range(len(filtered_all_data))):\n",
    "    pos_cut_file=pos_cut[file]\n",
    "    neg_cut_file=neg_cut[file]\n",
    "    for i in (tqdm(range(len(pos_cut_file)))):\n",
    "        pos_cut_file[i]=mask_cuts(pos_cut_file[i])\n",
    "        neg_cut_file[i]= mask_cuts(neg_cut_file[i])\n",
    "    pos_cut[file]=pos_cut_file\n",
    "    neg_cut[file]=neg_cut_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882845b7",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e721c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5577af82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#per canali con più di 30.000 spike, il massimo silhouette è sempre con 2 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae330f6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_clusters=[]\n",
    "for file in tqdm(range(len(filtered_all_data))):\n",
    "    #data=filtered_all_data[file]\n",
    "    #pos_cut_file=pos_cut[file]\n",
    "    #n_pos_file=n_pos[file]\n",
    "    final_data_pos=[]\n",
    "    for channel in (tqdm(range(len(pos_cut_file)))):\n",
    "        channel_clusters=clus(pos_cut[file][channel],'kmeans',n_pos[file][channel],filtered_all_data[file])\n",
    "        final_data_pos.append(channel_clusters)\n",
    "    pos_clusters.append(final_data_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e23a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neg_clusters=[]\n",
    "for file in tqdm(range(len(filtered_all_data))):\n",
    "    data=filtered_all_data[file]\n",
    "    neg_cut_file=neg_cut[file]\n",
    "    n_neg_file=n_neg[file]\n",
    "    final_data_neg=[]\n",
    "    for channel in (tqdm(range(len(neg_cut_file)))):\n",
    "        channel_clusters=clus(neg_cut_file[channel],'kmeans',n_neg_file[channel],data)\n",
    "        final_data_neg.append(channel_clusters)\n",
    "    neg_clusters.append(final_data_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ed4ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### verificare differenze tra kmeans e fuzzy c means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72415e0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neurons=[]\n",
    "for file in pos_clusters:\n",
    "    neurons_c=[]\n",
    "    for channel in file:\n",
    "        #neurons_c=[]\n",
    "        for neuron in channel:\n",
    "            neurons_c.append(neuron)\n",
    "        #neurons_f.append(neurons_c)\n",
    "    neurons.append(neurons_c)\n",
    "len(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe1e580",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pos_clusters))#files\n",
    "print(len(pos_clusters[0]))#channels\n",
    "print(len(pos_clusters[0][0]))#clusters\n",
    "print(len(pos_clusters[0][0][0]))#neuron indices for cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131d650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(neurons))#files\n",
    "print(len(neurons[0]))#clusters\n",
    "print(len(neurons[0][0]))#neuron indices of cluster\n",
    "#print(len(neurons[0][0][0]))#neuron indices of cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1fcd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_neurons[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c87203",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_neurons[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2565dfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7bcb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238b7517",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neurons[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188dea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11c526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06130adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in neg_clusters:\n",
    "    neurons_f=[]\n",
    "    for channel in file:\n",
    "        neurons_c=[]\n",
    "        for neuron in channel:\n",
    "            neurons_c.append(neuron)\n",
    "        neurons_f.append(neurons_c)\n",
    "    neurons.append(neurons_f)\n",
    "len(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250acccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neurons[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d42c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_neur=[]\n",
    "counter = 0\n",
    "max_len=0\n",
    "\n",
    "for file in neurons:\n",
    "    #for clus in file:\n",
    "    for neu in file:\n",
    "        print('counter: ',counter,neu.shape[0])\n",
    "        if neu.shape[0]>max_len:\n",
    "            max_len=neu.shape[0]\n",
    "        counter+=1\n",
    "    #counter=0\n",
    "print('max_len',max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a02a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in neurons:\n",
    "    adj_neur_f=[]\n",
    "    for neuron in file:\n",
    "        if neuron.shape[0]<=max_len:\n",
    "            diff = max_len-neuron.shape[0]\n",
    "            adj_neur_f.append(np.concatenate((neuron,np.zeros([diff]))))\n",
    "    adj_neur.append(adj_neur_f)\n",
    "#print(max_len)\n",
    "print(len(adj_neur),len(adj_neur[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a84f5b",
   "metadata": {},
   "source": [
    "# Export (after sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f854c24c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for i,file in enumerate(list_dir):\n",
    "    name_data=os.path.basename(list_dir[i])\n",
    "    save_data = 'After'+name_data\n",
    "    #np.savetxt(r\"C:\\Data after SS\\%save_data.txt\" % save_data,adj_neur[i], delimiter=', ', fmt='%12.8f')\n",
    "    np.savetxt(\"/Users/Gaia_1/Desktop/tesi/Data after SS/%s.txt\" % save_data,adj_neur[i], delimiter=', ', fmt='%12.8f')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19298a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cddbc90",
   "metadata": {},
   "source": [
    "# Point Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1863b9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bayesian_mixture_model(ISI_data):\n",
    "    with pm.Model() as model:\n",
    "        ##### WALD DISTRIBUTION (INVERSE GAUSSIAN)\n",
    "        mu1 = pm.Uniform('mu1',lower=0.01,upper=0.1)\n",
    "        lam1 = pm.Uniform('lam1',lower=0.01,upper=0.04)\n",
    "        obs1 = pm.Wald.dist(mu=mu1,lam=lam1)\n",
    "\n",
    "\n",
    "        mu2 = pm.Uniform('mu2',lower=0,upper=0.2)\n",
    "        sigma2 = pm.Uniform('sigma2',lower=0.0001,upper=0.5)\n",
    "        obs2 = pm.TruncatedNormal.dist(mu=mu2, sigma=sigma2, lower=0.0)\n",
    "\n",
    "        mu3 = pm.Uniform('mu3',lower=0.1,upper=0.6)\n",
    "        sigma3 = pm.Uniform('sigma3',lower=0.0001,upper=0.5)\n",
    "        obs3 = pm.TruncatedNormal.dist(mu=mu3, sigma=sigma3, lower=0.0)\n",
    "\n",
    "\n",
    "        w = pm.Dirichlet('w', a=np.array([1., .4, .4]))\n",
    "        #w = pm.Dirichlet('w', a=np.array([1., .4]))\n",
    "\n",
    "        like = pm.Mixture('like', w=w, comp_dists = [obs1, obs2, obs3], observed=ISI_data)\n",
    "        #like = pm.Mixture('like', w=w, comp_dists = [obs1, obs2], observed=ISI_data)\n",
    "\n",
    "        step = pm.NUTS(target_accept=0.9)\n",
    "        trace = pm.sample(step=step,draws=1000,chains=1,tune=1000,cores=4)\n",
    "        \n",
    "        #ppc_trace = pm.sample_posterior_predictive(trace,model=model)\n",
    "        \n",
    "    map_estimate = pm.find_MAP(model=model)\n",
    "    \n",
    "    del map_estimate['w_simplex__']\n",
    "    del map_estimate['mu1_interval__']\n",
    "    del map_estimate['lam1_interval__']\n",
    "    del map_estimate['mu2_interval__']\n",
    "    del map_estimate['sigma2_interval__']\n",
    "    del map_estimate['mu3_interval__']\n",
    "    del map_estimate['sigma3_interval__']\n",
    "    \n",
    "    map_estimate['w1'] = map_estimate['w'][0]\n",
    "    map_estimate['w2'] = map_estimate['w'][1]\n",
    "    map_estimate['w3'] = map_estimate['w'][2]\n",
    "\n",
    "    del map_estimate['w']\n",
    "\n",
    "\n",
    "    return map_estimate#, ppc_trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b371e100",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dir=glob.glob(\"Data after SS/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6c6eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dir_ok = []\n",
    "for net in list_dir:\n",
    "    #if 'After' not in net:\n",
    "        print(net,'ok')\n",
    "        list_dir_ok.append(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b61da4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame()\n",
    "counter_net=1\n",
    "counter=0\n",
    "target = 0\n",
    "for net in list_dir_ok:\n",
    "    print(counter_net,') ',net)\n",
    "    counter_net+=1\n",
    "    list_neurons = np.genfromtxt(net, delimiter=',')\n",
    "    counter=0\n",
    "    print('Original number of neurons: ',len(list_neurons))\n",
    "    for neuron in list_neurons:\n",
    "        neuron=neuron[neuron>0*10000]\n",
    "        neuron=neuron[neuron<200*10000]\n",
    "        print('  Neuron with ',neuron.shape[0],'spikes')\n",
    "        if neuron.shape[0]>800:\n",
    "            \n",
    "            counter+=1\n",
    "        else:\n",
    "            print('    Excluded neuron with n spikes = ',neuron.shape[0])\n",
    "            continue\n",
    "        \n",
    "        ISI_healthy = np.diff(neuron)/10000\n",
    "        \n",
    "            \n",
    "        map_estimate = Bayesian_mixture_model(ISI_healthy)\n",
    "        \n",
    "        if 'Healthy' in net:\n",
    "            print('target Healthy')\n",
    "            map_estimate['Target']=0\n",
    "            \n",
    "        elif 'healthy' in net:\n",
    "            print('target healthy')\n",
    "            map_estimate['Target']=0\n",
    "        elif 'health' in net:\n",
    "            print('target health')\n",
    "            map_estimate['Target']=0\n",
    "\n",
    "        else:\n",
    "            print('target pathological')\n",
    "            map_estimate['Target']=1\n",
    "        \n",
    "        if 'KA' in net:\n",
    "            map_estimate['Stimulation']=1\n",
    "            \n",
    "        elif 'stimulation' in net:\n",
    "            map_estimate['Stimulation']=1\n",
    "        else:\n",
    "            map_estimate['Stimulation']=0\n",
    "            \n",
    "        df = pd.DataFrame.from_dict(map_estimate,orient='index')\n",
    "        dataframe = pd.concat([dataframe,df],axis = 1)\n",
    "    print('Final number of neurons: ',counter)\n",
    "    print('Target = ',target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eed145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = dataframe.T\n",
    "final.to_csv('Data after PP/DataAfter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effdd44b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "417c1072",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab466a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Data after PP/DataAfter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea9846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22b3ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dadfba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95416c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = dataset.drop(['Target'],axis=1)\n",
    "y= dataset['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.25,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4924da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b0f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c6248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3,svd_solver='full')\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(pca.fit(X_train).explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa869b9f",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'max_depth':np.linspace(2,10,dtype='int'),'criterion':['gini','entropy']}\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=12)\n",
    "\n",
    "gs = GridSearchCV(clf, params, scoring='roc_auc',cv=cv,n_jobs=-1)\n",
    "\n",
    "gs=gs.fit(X_train,y_train)\n",
    "\n",
    "gs_pca = GridSearchCV(clf, params, scoring='roc_auc',cv=cv,n_jobs=-1)\n",
    "gs_pca = gs_pca.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5850dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"Best parameters set found :\",gs.best_params_,'\\n')\n",
    "print(\"Classification report on Test set\\n\")\n",
    "\n",
    "y_true, y_pred = y_test, gs.predict(X_test)\n",
    "\n",
    "accuracy = round(accuracy_score(y_true, y_pred),3)\n",
    "recall = round(recall_score(y_true, y_pred),3)\n",
    "precision = round(precision_score(y_true, y_pred),3)\n",
    "#roc_auc = round(roc_auc_score(y_true, y_pred),3)\n",
    "\n",
    "print('Accuracy: ',accuracy)\n",
    "print('Recall: ',recall)\n",
    "print('Precision: ',precision)\n",
    "#print('ROC AUC: ',roc_auc)\n",
    "print('\\n\\n Result with PCA\\n')\n",
    "print(\"Best parameters set found :\",gs_pca.best_params_,'\\n')\n",
    "print(\"Classification report on Test set\\n\")\n",
    "\n",
    "y_true, y_pred = y_test, gs_pca.predict(X_test_pca)\n",
    "\n",
    "accuracy = round(accuracy_score(y_true, y_pred),3)\n",
    "recall = round(recall_score(y_true, y_pred),3)\n",
    "precision = round(precision_score(y_true, y_pred),3)\n",
    "#roc_auc = round(roc_auc_score(y_true, y_pred),3)\n",
    "\n",
    "print('Accuracy: ',accuracy)\n",
    "print('Recall: ',recall)\n",
    "print('Precision: ',precision)\n",
    "#print('ROC AUC: ',roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055dae26",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7522c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C':np.logspace(-3,3,50),'penalty':['l1','l2','elasticnet']}\n",
    "\n",
    "clf = LogisticRegression(solver='liblinear',random_state=12)\n",
    "\n",
    "gs = GridSearchCV(clf, params, scoring='roc_auc',cv=cv,n_jobs=-1)\n",
    "\n",
    "gs=gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8b5d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found :\",gs.best_params_,'\\n')\n",
    "print(\"Classification report on Test set\\n\")\n",
    "\n",
    "y_true, y_pred = y_test, gs.predict(X_test)\n",
    "\n",
    "accuracy = round(accuracy_score(y_true, y_pred),3)\n",
    "recall = round(recall_score(y_true, y_pred),3)\n",
    "precision = round(precision_score(y_true, y_pred),3)\n",
    "roc_auc = round(roc_auc_score(y_true, y_pred),3)\n",
    "\n",
    "print('Accuracy: ',accuracy)\n",
    "print('Recall: ',recall)\n",
    "print('Precision: ',precision)\n",
    "print('ROC AUC: ',roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86190f9",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af00d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators':np.linspace(10,150,dtype='int',num=10),'max_depth':np.linspace(2,5,dtype='int'),'criterion':['gini','entropy']}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1,random_state=12)\n",
    "\n",
    "gs = GridSearchCV(clf, params, scoring='roc_auc',cv=cv,verbose=10,n_jobs=-1)\n",
    "\n",
    "gs=gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e306511",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found :\",gs.best_params_,'\\n')\n",
    "print(\"Classification report on Test set\\n\")\n",
    "\n",
    "y_true, y_pred = y_test, gs.predict(X_test)\n",
    "\n",
    "accuracy = round(accuracy_score(y_true, y_pred),3)\n",
    "recall = round(recall_score(y_true, y_pred),3)\n",
    "precision = round(precision_score(y_true, y_pred),3)\n",
    "roc_auc = round(roc_auc_score(y_true, y_pred),3)\n",
    "\n",
    "print('Accuracy: ',accuracy)\n",
    "print('Recall: ',recall)\n",
    "print('Precision: ',precision)\n",
    "print('ROC AUC: ',roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014866df",
   "metadata": {},
   "source": [
    "Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526cd7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            20, activation=\"relu\", input_shape=(X_train.shape[1],)\n",
    "        ),\n",
    "        keras.layers.Dense(100, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(50, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62297ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    'accuracy',\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "history=model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=10,\n",
    "    epochs=200,\n",
    "    validation_data=(X_test, y_test),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df53120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59709887",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test, model.predict_classes(X_test)\n",
    "\n",
    "accuracy = round(accuracy_score(y_true, y_pred),3)\n",
    "recall = round(recall_score(y_true, y_pred),3)\n",
    "precision = round(precision_score(y_true, y_pred),3)\n",
    "roc_auc = round(roc_auc_score(y_true, y_pred),3)\n",
    "\n",
    "print('Accuracy: ',accuracy)\n",
    "print('Recall: ',recall)\n",
    "print('Precision: ',precision)\n",
    "print('ROC AUC: ',roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7efaac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a58a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0c2079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283cd747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
