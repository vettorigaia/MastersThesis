{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8babe8d2",
   "metadata": {},
   "source": [
    "# Spike sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe226e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#da fare:\n",
    "# soglia silhouette >0.4 (non >=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5933ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_neurons=[]\n",
    "from NewLibraryENGcopia import *\n",
    "import glob\n",
    "#final=[]\n",
    "list_dir=glob.glob(\"/Users/Gaia_1/Desktop/allh5filestutto/*\")\n",
    "output_path='/Users/Gaia_1/Desktop/tesi/Data after SS'\n",
    "for file in tqdm(list_dir):\n",
    "    target=1\n",
    "    stim=0\n",
    "    if 'health' in file:\n",
    "        target=0\n",
    "    if 'stimulation' in file:\n",
    "        stim=1\n",
    "    file_name = file.split(\"/\")[-1]\n",
    "    print(file_name,':','target',target,'stimulation',stim)\n",
    "    neurons=spike_sorting(file,output_path)\n",
    "    #df=poiproc(neurons,target,stim)\n",
    "    #final.append(df)\n",
    "    final_neurons.append(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd45f217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Gaia_1/Desktop/allh5filestutto/2018-11-27T10-03-29MIP4 BL .h5\n",
      "/Users/Gaia_1/Desktop/allh5filestutto/2018-11-27T09-38-09MIP 2 BL .h5\n",
      "/Users/Gaia_1/Desktop/allh5filestutto/2019-01-23T16-22-47Pop3 healthy cortical stimulation modifiedname.h5\n",
      "/Users/Gaia_1/Desktop/allh5filestutto/2018-11-27T11-24-28MiP3 stimulation.h5\n",
      "/Users/Gaia_1/Desktop/allh5filestutto/2019-01-23T15-36-26MEA3 healthy cortical stimulation modifiedname.h5\n",
      "/Users/Gaia_1/Desktop/allh5filestutto/zzdone\n",
      "/Users/Gaia_1/Desktop/allh5filestutto/2019-01-23T11-41-41Pop1 healthy cortical .h5\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "list_dir=glob.glob(\"/Users/Gaia_1/Desktop/allh5filestutto/*\")\n",
    "for file in list_dir:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16df5b6",
   "metadata": {},
   "source": [
    "# Point Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99f8455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NewLibraryENGcopia import *\n",
    "import glob\n",
    "final=[]\n",
    "output_path='/Users/Gaia_1/Desktop/tesi/Data after SS'\n",
    "list_dir=glob.glob(output_path+\"/*\")\n",
    "for file in tqdm(list_dir):\n",
    "    target=1\n",
    "    stim=0\n",
    "    if 'health' in file:\n",
    "        target=0\n",
    "    if 'stimulation' in file:\n",
    "        stim=1\n",
    "    list_neurons = np.genfromtxt(file, delimiter=',')\n",
    "    df,counter=poiproc(list_neurons,target,stim)\n",
    "    final.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a10e9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d42f2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0b7785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NewLibraryENGcopia import *\n",
    "\n",
    "#POPULATION 1 (HEALTHY):\n",
    "name_data1 = '2019-01-23T11-19-05PoP1 healthy cortical .h5'\n",
    "complete_string_BL='/Users/Gaia_1/Desktop/allh5files/healthy/healthy_baseline/'+name_data1\n",
    "name_data2 = '2019-01-23T16-06-32Pop1 healthy cortical .h5'\n",
    "complete_string_st='/Users/Gaia_1/Desktop/allh5files/healthy/healthy_stimulation/'+name_data2\n",
    "name_data3 = '2019-01-24T16-00-33Pop1 24hour after.h5'\n",
    "complete_string_post='/Users/Gaia_1/Desktop/allh5files/healthy/healthy 24hrs later/'+name_data3\n",
    "\n",
    "# POPULATION 1 (LKRR2):\n",
    "name_data4='2018-11-27T10-17-41POP 1 BL .h5'\n",
    "complete_string_BL_LKRR2='/Users/Gaia_1/Desktop/allh5files/LRRK2/lkkr2 baseline/'+name_data4\n",
    "name_data5='2018-11-27T11-50-12POP 1 control.h5'\n",
    "complete_string_st_LKRR2='/Users/Gaia_1/Desktop/allh5files/LRRK2/lkkr2 stimulation/'+name_data5\n",
    "name_data6='2018-11-28T12-22-45Pop1 control.h5'\n",
    "complete_string_post_LKRR2='/Users/Gaia_1/Desktop/allh5files/LRRK2/lkkr2 24hrs post/'+name_data6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac341de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from NewLibraryENGcopia import *\n",
    "import glob\n",
    "final=[]\n",
    "target=1\n",
    "stim=1\n",
    "list_dir=glob.glob(\"/Users/Gaia_1/Desktop/allh5files/*\")\n",
    "for targets in list_dir:\n",
    "    #healthy and LKRR2\n",
    "    if 'healthy' in targets:\n",
    "        target=0\n",
    "        print('healthy')\n",
    "    folder=glob.glob(targets+'/*')\n",
    "    for phase in folder:\n",
    "        #BL, stim, 24hrs post\n",
    "        if 'baseline' in phase:\n",
    "            stim=0\n",
    "            print('baseline')\n",
    "        final_folders=glob.glob(phase+'/*.h5')\n",
    "        for file in tqdm(final_folders):\n",
    "            #all files\n",
    "            file_name = file.split(\"/\")[-1]\n",
    "            print(file_name,':')\n",
    "            neurons=spike_sorting(file_name,file,0,'kmeans',4,2)\n",
    "            df=poiproc(neurons,target,stim)\n",
    "            final.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e586f45e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e74baf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5371692",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, .5, 1e-3) \n",
    "plt.figure (figsize=(14,10))\n",
    "hist = np.histogram(ppc_trace['posterior_predictive']['like'].values,bins=bins)\n",
    "#plt.axis([-0.01,0.13,0,160])\n",
    "a= plt.hist(ISI_healthy,bins)\n",
    "plt.plot(hist[1][:-1],hist[0]/1000,linewidth=3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf106785",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_samples=[]\n",
    "for i in list(ppc_trace['posterior_predictive']['like'].values):\n",
    "    lista_samples.extend(i)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85271c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, _ = np.histogram(ISI_healthy, bins) \n",
    "prob_emp = counts / np.sum(counts)\n",
    "counts, _ = np.histogram(lista_samples, bins) \n",
    "prob_model = counts / np.sum(counts)\n",
    "\n",
    "Femp = np.cumsum(prob_emp)           \n",
    "Fmodel = np.cumsum(prob_model)          \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(bins[:-1], Femp)                \n",
    "plt.plot(bins[:-1], Fmodel, 'r')       \n",
    "#plt.xlim([0, 0.2])                  \n",
    "#plt.xlabel('Time [s]')\n",
    "#plt.ylabel('CDF')\n",
    "plt.legend(['Empirical','Model'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79da4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "Nlow = len(ISI_healthy)  \n",
    "# Plot the confidence bounds\n",
    "plt.plot([0, 1], [x + 1.36 / np.sqrt(Nlow) for x in [0, 1]], 'r:')\n",
    "plt.plot([0, 1], [x - 1.36 / np.sqrt(Nlow) for x in [0, 1]], 'r:')\n",
    "plt.plot(Femp, Fmodel)\n",
    "#plt.axis([0, 1, 0, 1])         \n",
    "#plt.xlabel('Model CDF')\n",
    "#plt.ylabel('Empirical CDF')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3b6cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2a4970",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame()\n",
    "list_neurons = neurons\n",
    "counter=0\n",
    "target=0\n",
    "print('Original number of neurons: ',len(list_neurons))\n",
    "for neuron in list_neurons:\n",
    "    neuron=neuron[neuron>0*10000]\n",
    "    neuron=neuron[neuron<200*10000]\n",
    "    print('  Neuron with ',neuron.shape[0],'spikes')\n",
    "    if neuron.shape[0]>100:\n",
    "\n",
    "        counter+=1\n",
    "    else:\n",
    "        print('    Excluded neuron with n spikes = ',neuron.shape[0])\n",
    "        continue\n",
    "\n",
    "    ISI_healthy = np.diff(neuron)/10000\n",
    "\n",
    "\n",
    "    map_estimate,ppc_trace = this_Bayesian_mixture_model(ISI_healthy)\n",
    "    #trace(ppc_trace)\n",
    "    df = pd.DataFrame.from_dict(map_estimate,orient='index')\n",
    "    dataframe = pd.concat([dataframe,df],axis = 1)\n",
    "print('Final number of neurons: ',counter)\n",
    "print('Target = ',target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80154ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def this_Bayesian_mixture_model(ISI_data):\n",
    "    with pm.Model() as model:\n",
    "        ##### WALD DISTRIBUTION (INVERSE GAUSSIAN)\n",
    "        mu1 = pm.Uniform('mu1',lower=0.01,upper=0.1)\n",
    "        lam1 = pm.Uniform('lam1',lower=0.001,upper=0.04)\n",
    "        obs1 = pm.Wald.dist(mu=mu1,lam=lam1)\n",
    "\n",
    "\n",
    "        mu2 = pm.Uniform('mu2',lower=0,upper=0.2)\n",
    "        sigma2 = pm.Uniform('sigma2',lower=0.0001,upper=0.5)\n",
    "        obs2 = pm.TruncatedNormal.dist(mu=mu2, sigma=sigma2, lower=0.0)\n",
    "\n",
    "        mu3 = pm.Uniform('mu3',lower=0.1,upper=0.6)\n",
    "        sigma3 = pm.Uniform('sigma3',lower=0.0001,upper=0.5)\n",
    "        obs3 = pm.TruncatedNormal.dist(mu=mu3, sigma=sigma3, lower=0.0)\n",
    "\n",
    "\n",
    "        w = pm.Dirichlet('w', a=np.array([1., .4, .4]))\n",
    "        #w = pm.Dirichlet('w', a=np.array([1., .4]))\n",
    "\n",
    "        like = pm.Mixture('like', w=w, comp_dists = [obs1, obs2, obs3], observed=ISI_data)\n",
    "        #like = pm.Mixture('like', w=w, comp_dists = [obs1, obs2], observed=ISI_data)\n",
    "\n",
    "        step = pm.NUTS(target_accept=0.9)\n",
    "        trace = pm.sample(step=step,draws=1000,chains=4,tune=1000,cores=4)\n",
    "        \n",
    "        ppc_trace = pm.sample_posterior_predictive(trace,model=model)\n",
    "        if ppc_trace==0:\n",
    "            print('ppc_trace not succesful')\n",
    "        '''\n",
    "        bins = np.arange(0, .5, 1e-3) \n",
    "        plt.figure (figsize=(14,10))\n",
    "        hist = np.histogram(ppc_trace['posterior_predictive']['like'].values,bins=bins)\n",
    "        #plt.axis([-0.01,0.13,0,160])\n",
    "        a= plt.hist(ISI_healthy,bins)\n",
    "        plt.plot(hist[1][:-1],hist[0]/1000,linewidth=3)\n",
    "        plt.show()\n",
    "\n",
    "        lista_samples=[]\n",
    "        for i in list(ppc_trace['posterior_predictive']['like'].values):\n",
    "            lista_samples.extend(i)        \n",
    "        \n",
    "        counts, _ = np.histogram(ISI_healthy, bins) \n",
    "        prob_emp = counts / np.sum(counts)\n",
    "        counts, _ = np.histogram(lista_samples, bins) \n",
    "        prob_model = counts / np.sum(counts)\n",
    "\n",
    "        Femp = np.cumsum(prob_emp)           \n",
    "        Fmodel = np.cumsum(prob_model)          \n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(bins[:-1], Femp)                \n",
    "        plt.plot(bins[:-1], Fmodel, 'r')       \n",
    "        #plt.xlim([0, 0.2])                  \n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('CDF')\n",
    "        plt.legend(['Empirical','Model'])\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        Nlow = len(ISI_healthy)  \n",
    "        # Plot the confidence bounds\n",
    "        plt.plot([0, 1], [x + 1.36 / np.sqrt(Nlow) for x in [0, 1]], 'r:')\n",
    "        plt.plot([0, 1], [x - 1.36 / np.sqrt(Nlow) for x in [0, 1]], 'r:')\n",
    "        plt.plot(Femp, Fmodel)\n",
    "        #plt.axis([0, 1, 0, 1])         \n",
    "        plt.xlabel('Model CDF')\n",
    "        plt.ylabel('Empirical CDF')\n",
    "        plt.show()\n",
    "        '''\n",
    "        \n",
    "    map_estimate = pm.find_MAP(model=model)\n",
    "    \n",
    "    del map_estimate['w_simplex__']\n",
    "    del map_estimate['mu1_interval__']\n",
    "    del map_estimate['lam1_interval__']\n",
    "    del map_estimate['mu2_interval__']\n",
    "    del map_estimate['sigma2_interval__']\n",
    "    del map_estimate['mu3_interval__']\n",
    "    del map_estimate['sigma3_interval__']\n",
    "    \n",
    "    map_estimate['w1'] = map_estimate['w'][0]\n",
    "    map_estimate['w2'] = map_estimate['w'][1]\n",
    "    map_estimate['w3'] = map_estimate['w'][2]\n",
    "\n",
    "    del map_estimate['w']\n",
    "\n",
    "\n",
    "    return map_estimate, ppc_trace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
