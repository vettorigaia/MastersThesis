{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc67d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pi√π canali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9107b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LibraryENGcopia import *\n",
    "from tqdm.notebook import tqdm\n",
    "import sklearn.preprocessing as ps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from random import randint\n",
    "from fastdtw import fastdtw\n",
    "import copy\n",
    "import pymc as pm\n",
    "name_data = '2018-11-27T10-29-42POP 2 BL .h5'\n",
    "name_data2 = '2018-11-27T12-03-02POP 2 stimulation.h5'\n",
    "name_data3='2018-11-27T10-56-39MiP5 KA stimulation.h5'\n",
    "name_data4='2018-11-27T11-24-28MiP3 stimulation.h5'\n",
    "name_data5='2018-11-27T10-40-53POP 3 BL .h5'\n",
    "complete_string='/Users/Gaia_1/Downloads/PoiProMEA-master/h5files/'+name_data\n",
    "complete_string2='/Users/Gaia_1/Downloads/PoiProMEA-master/h5files/'+name_data2\n",
    "complete_string3='/Users/Gaia_1/Downloads/PoiProMEA-master/h5files/'+name_data3\n",
    "complete_string4='/Users/Gaia_1/Downloads/PoiProMEA-master/h5files/'+name_data4\n",
    "complete_string5='/Users/Gaia_1/Downloads/PoiProMEA-master/h5files/'+name_data5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8597abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = h5py.File(complete_string,'r')\n",
    "#data = h5py.File(complete_string2,'r')\n",
    "#data = h5py.File(complete_string3,'r')\n",
    "data = h5py.File(complete_string4,'r') #Stimulated\n",
    "#data = h5py.File(complete_string5,'r') #BL\n",
    "\n",
    "data_readings = data['Data']['Recording_0']['AnalogStream']['Stream_0']['ChannelData'][()]\n",
    "info = data['Data']['Recording_0']['AnalogStream']['Stream_0']['InfoChannel'][()]\n",
    "info_table = pd.DataFrame(info, columns = list(info.dtype.fields.keys()))\n",
    "labels = info_table['Label']\n",
    "readings = pd.DataFrame(data = data_readings.transpose(), columns = labels)\n",
    "fs = 10000 #Sampling Frequency\n",
    "print(readings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c4b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "inizio=0\n",
    "#len_data=810000 #192 secondi\n",
    "len_data=len(readings)\n",
    "prova=readings.iloc[inizio:len_data, 10:17]\n",
    "prova=prova.drop([b'Ref'],axis=1)\n",
    "ref=readings[b'Ref']\n",
    "ref=ref[inizio:len_data]\n",
    "\n",
    "print(prova.shape,ref.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cd53a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prova_rows = range(prova.shape[0])\n",
    "filt_prova = pd.DataFrame(data = 0, columns=prova.columns, index=prova_rows, dtype = \"float32\")\n",
    "lowcut = 300\n",
    "highcut = 3000\n",
    "fs=10000\n",
    "order=8\n",
    "b,a=butter_bandpass(lowcut,highcut,fs,order=order)\n",
    "filt_ref=filtfilt(b,a,ref)\n",
    "#ref_df = pd.DataFrame({b'Ref': filt_ref})\n",
    "for x in tqdm(range(prova.shape[1])):\n",
    "    filt_prova.values[:,x] = scipy.signal.filtfilt(b, a, prova.values[:,x])\n",
    "for electrode in prova.columns:\n",
    "    filt_prova[electrode] = filt_prova[electrode] - filt_ref\n",
    "#filt_prova = pd.concat([filt_prova, ref_df], axis=1)\n",
    "prova=filt_prova\n",
    "prova.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d216ef31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eed210bb",
   "metadata": {},
   "source": [
    "# Spike detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f7951",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ind=[]\n",
    "neg_ind=[]\n",
    "for electrode in tqdm(prova.columns):\n",
    "    channel=prova[electrode]\n",
    "    pos, neg=find_all_spikes(channel)\n",
    "    pos_ind.append(pos)\n",
    "    neg_ind.append(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac758d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b565d61",
   "metadata": {},
   "source": [
    "BL: window 3000 (threshold 4 MAD) firing 18    \n",
    "BL: window 300 (thresh 3), firing 89    \n",
    "KA: window 3000 (thresh 3), firing 94    \n",
    "KA: window 3000 (thresh 4), firing 29    \n",
    "KA: window 300, (thresh 4) firing 39   \n",
    "KA: window 300, (thresh 3) firing 108   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ec8cc4",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(30, 15))\n",
    "plt.plot(prova, label='Signal Data')\n",
    "plt.scatter(pos, [prova[i] for i in pos], c='red', marker='o', label='Local Maxima')\n",
    "plt.scatter(neg, [prova[i] for i in neg], c='green', marker='o', label='Local Minima')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Signal Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Signal Data with Detected Spikes')\n",
    "#plt.axis([0,3000,-5,5])\n",
    "#plt.savefig('spikes1.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddba0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b355436f",
   "metadata": {},
   "source": [
    "minima,maxima=RMM(prova)\n",
    "print(len(maxima))\n",
    "#segnale BASELINE: firing rate=70 (spikes 26148)\n",
    "#segnale Stimulation: firing rate=69 (spikes 32980)\n",
    "#segnale KA stimulation: firing rate=81 (spikes 47860)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a7067",
   "metadata": {},
   "source": [
    "minima,maxima=find_spikes(prova)\n",
    "len(maxima)\n",
    "#segnale BASELINE: firing rate=27 (spikes 10276)\n",
    "#segnale Stimulation: firing rate=27 (spikes 13198)\n",
    "#segnale KA stimulation: firing rate=32 (spikes 19178)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5256bf0b",
   "metadata": {},
   "source": [
    "minima,maxima=find_spikes_with_memory(prova)\n",
    "len(maxima)\n",
    "#segnale BASELINE: firing rate=25 (spikes 9270)\n",
    "#segnale Stimulation: firing rate=22 (spikes 10579)\n",
    "#segnale KA stimulation: firing rate=8 (spikes 5054)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76991121",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(30, 15))\n",
    "plt.plot(prova, label='Signal Data')\n",
    "plt.scatter(minima, [prova[i] for i in minima], c='red', marker='o', label='Local Minima')\n",
    "plt.scatter(maxima, [prova[i] for i in maxima], c='green', marker='x', label='Local maxima')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Signal Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Signal Data with Detected Spikes')\n",
    "#plt.axis([0,30000,-5,5])\n",
    "#plt.savefig('spikes2.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8f5432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc55e4f8",
   "metadata": {},
   "source": [
    "# Cutouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead6842",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pos_cut=[]\n",
    "neg_cut=[]\n",
    "n_pos=[]\n",
    "n_neg=[]\n",
    "\n",
    "for i,electrode in enumerate(tqdm(prova.columns)):\n",
    "    pos=pos_ind[i]\n",
    "    neg=neg_ind[i]\n",
    "    channel=prova[electrode]\n",
    "    pos_cut1,n_pos1, neg_cut1,n_neg1 = cut(pos,neg,channel)\n",
    "    pos_cut.append(pos_cut1)\n",
    "    neg_cut.append(neg_cut1)\n",
    "    n_pos.append(n_pos1)\n",
    "    n_neg.append(n_neg1)\n",
    "savedp = copy.deepcopy(pos_cut)\n",
    "savedn = copy.deepcopy(neg_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15977543",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (tqdm(range(len(pos_cut)))):\n",
    "    pos_cut[i]=mask_cuts(pos_cut[i])\n",
    "    neg_cut[i]= mask_cuts(neg_cut[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212338ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x=randint(1,min(len(pos_cut),len(neg_cut)))\n",
    "y=randint(1,min(len(pos_cut[x]),len(neg_cut[x])))\n",
    "plt.plot(savedp[x][y])\n",
    "plt.plot(pos_cut[x][y])\n",
    "plt.show()\n",
    "#plt.plot(savedn[x])\n",
    "#plt.plot(neg_cut[x])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c20954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ba5d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fa2e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaabeff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dba03b7",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "pca = PCA()\n",
    "pca.fit(pos_cut)\n",
    "explained_variances = pca.explained_variance_ratio_\n",
    "explained_variance_df = pd.DataFrame(data={'Explained Variance': explained_variances},\n",
    "                                     index=range(1, len(explained_variances) + 1))\n",
    "explained_variance_df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67be79a",
   "metadata": {},
   "source": [
    "cumulative_explained_variance = np.cumsum(explained_variances)\n",
    "cumulative_explained_variance_df = pd.DataFrame(data={'Cumulative Explained Variance': cumulative_explained_variance},\n",
    "                                                index=range(1, len(cumulative_explained_variance) + 1))\n",
    "cumulative_explained_variance_df.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ef327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd0ea887",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da45eec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_data_pos=[]\n",
    "for channel in (tqdm(range(len(pos_cut)))):\n",
    "    channel_clusters= hdbscan_clustering(pos_cut[channel],n_pos[channel],len_data)\n",
    "    final_data_pos.append(channel_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1668da9d",
   "metadata": {},
   "source": [
    "BL (window 3000, thresh 4) (less function) fuzzy (1.8, 4, 3.99)   \n",
    "BL (window 300) (less function) fuzzy (19, 18, 9)   \n",
    "BL (window 300) (less function) dbscan (30, 9)   \n",
    "BL (window 300) (bit less function std) fuzzy (8.9, 18.2, 17.8)   \n",
    "BL (window 300) (more cut function) fuzzy (8.9, 17.7, 18.3)   \n",
    "BL (window 300) (more cut function) dbscan (29, 6)   \n",
    "BL (less cut function) fuzzy: (15, 8 ,15)   \n",
    "\n",
    "KA (window 300, thresh 4) (less function) fuzzy (3.8, 4, 1.9)   \n",
    "KA (window 3000, thresh 4) (less function) fuzzy (2.6, 1.2, 2.8)   \n",
    "KA stimualtion 3 clusters fuzzy: (13, 6, 12)   \n",
    "KA stim (window 300) (new cut function) (1.17,2.55,2.37)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87b9e17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_data_neg=[]\n",
    "for i in (tqdm(range(len(neg_cut)))):\n",
    "    channel_clusters= hdbscan_clustering(neg_cut[channel],n_neg[channel],len_data)\n",
    "    final_data_neg.append(channel_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2b9409",
   "metadata": {},
   "source": [
    "BL (less cut function) (window 3000, thresh4) fuzzy: (3.5, 3.5, 1.6) silhouette: 0.231    \n",
    "BL (less cut function) (window 300) fuzzy: (17, 15, 6) silhouette: 0.215    \n",
    "BL (more cut function) (window 300) fuzzy: (15, 16, 7) silhouette: 0.218    \n",
    "BL (less cut function) fuzzy: (13, 13, 6) silhouette: 0.226    \n",
    "\n",
    "KA (less cut function) (window 300, thresh4) fuzzy: (1.9, 1.12, 1.9) silhouette: 0.229   \n",
    "KA (less cut function) (window 3000, thresh4) fuzzy: (1.4, 0.89, 1.4) silhouette: 0.223    \n",
    "KA stimulation 3 clusters fuzzy: (3.9, 3.7, 2) silhouette: 0.214    \n",
    "KA stimulation (more cut function) (window 3000) fuzzy: (2, 3.9, 3.7) silhouette: 0.214    \n",
    "KA stimulation (more cut function) (window 300) fuzzy (4.5, 4.4, 2.2) silhouette: 0.204    \n",
    "KA stimulation (more cut function) (window 300) dbscan (10.8,10.8)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad239a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = []\n",
    "for electrode in final_data_pos:\n",
    "    for neuron in electrode:\n",
    "        neurons.append(neuron)\n",
    "for neuron final_data_neg:\n",
    "    for neuron in electrode:\n",
    "        neurons.append(neuron)\n",
    "neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032f1842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6b2842",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_neur=[]\n",
    "counter = 0\n",
    "max_len=0\n",
    "\n",
    "for neu in neurons:\n",
    "    print('counter: ',counter,neu.shape[0])\n",
    "    if neu.shape[0]>max_len:\n",
    "        max_len=neu.shape[0]\n",
    "    counter+=1\n",
    "for neuron in neurons:\n",
    "    if neuron.shape[0]<=max_len:\n",
    "        diff = max_len-neuron.shape[0]\n",
    "        adj_neur.append(np.concatenate((neuron,np.zeros([diff]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72247e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_healthy=adj_neur[2]\n",
    "ISI_healthy = np.diff(data_healthy)/10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac710f3",
   "metadata": {},
   "source": [
    "## Point Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4112e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ISI_data=ISI_healthy\n",
    "\n",
    "def Bayesian_mixture_model(ISI_data):\n",
    "    with pm.Model() as model:\n",
    "        ##### WALD DISTRIBUTION (INVERSE GAUSSIAN)\n",
    "        mu1 = pm.Uniform('mu1',lower=0.01,upper=0.1)\n",
    "        lam1 = pm.Uniform('lam1',lower=0.01,upper=0.04)\n",
    "        obs1 = pm.Wald.dist(mu=mu1,lam=lam1)\n",
    "\n",
    "\n",
    "        mu2 = pm.Uniform('mu2',lower=0,upper=0.2)\n",
    "        sigma2 = pm.Uniform('sigma2',lower=0.0001,upper=0.5)\n",
    "        obs2 = pm.TruncatedNormal.dist(mu=mu2, sigma=sigma2, lower=0.0)\n",
    "\n",
    "        mu3 = pm.Uniform('mu3',lower=0.1,upper=0.6)\n",
    "        sigma3 = pm.Uniform('sigma3',lower=0.0001,upper=0.5)\n",
    "        obs3 = pm.TruncatedNormal.dist(mu=mu3, sigma=sigma3, lower=0.0)\n",
    "\n",
    "\n",
    "        w = pm.Dirichlet('w', a=np.array([1., .4, .4]))\n",
    "        #w = pm.Dirichlet('w', a=np.array([1., .4]))\n",
    "\n",
    "        like = pm.Mixture('like', w=w, comp_dists = [obs1, obs2, obs3], observed=ISI_data)\n",
    "        #like = pm.Mixture('like', w=w, comp_dists = [obs1, obs2], observed=ISI_data)\n",
    "        map_estimate = pm.find_MAP(model=model)\n",
    "\n",
    "        step = pm.NUTS(target_accept=0.9)\n",
    "        trace = pm.sample(step=step,draws=1000,chains=1,tune=1000,cores=4)\n",
    "\n",
    "        del map_estimate['w_simplex__']\n",
    "        del map_estimate['mu1_interval__']\n",
    "        del map_estimate['lam1_interval__']\n",
    "        del map_estimate['mu2_interval__']\n",
    "        del map_estimate['sigma2_interval__']\n",
    "        del map_estimate['mu3_interval__']\n",
    "        del map_estimate['sigma3_interval__']\n",
    "\n",
    "        map_estimate['w1'] = map_estimate['w'][0]\n",
    "        map_estimate['w2'] = map_estimate['w'][1]\n",
    "        map_estimate['w3'] = map_estimate['w'][2]\n",
    "\n",
    "        del map_estimate['w']\n",
    "\n",
    "\n",
    "        return map_estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe8561",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    ppc_trace = pm.sample_posterior_predictive(trace,model=model)\n",
    "\n",
    "bins = np.arange(0, .5, 1e-3) \n",
    "plt.figure (figsize=(14,10))\n",
    "\n",
    "hist = np.histogram(ppc_trace['posterior_predictive']['like'].values,bins=bins)\n",
    "#plt.axis([0,0.3,0,160])\n",
    "a= plt.hist(ISI_healthy,bins)\n",
    "plt.plot(hist[1][:-1],hist[0]/1000,linewidth=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ed7020",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_samples=[]\n",
    "for i in list(ppc_trace['posterior_predictive']['like'].values):\n",
    "    lista_samples.extend(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87bf175",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, _ = np.histogram(ISI_healthy, bins) \n",
    "prob_emp = counts / np.sum(counts)\n",
    "counts, _ = np.histogram(lista_samples, bins) \n",
    "prob_model = counts / np.sum(counts)\n",
    "\n",
    "Femp = np.cumsum(prob_emp)           \n",
    "Fmodel = np.cumsum(prob_model)          \n",
    "plt.figure()\n",
    "plt.plot(bins[:-1], Femp)                \n",
    "plt.plot(bins[:-1], Fmodel, 'r')       \n",
    "#plt.xlim([0, 0.2])                  \n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('CDF')\n",
    "plt.legend(['Empirical','Model'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc155ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "Nlow = len(ISI_healthy)  \n",
    "# Plot the confidence bounds\n",
    "plt.plot([0, 1], [x + 1.36 / np.sqrt(Nlow) for x in [0, 1]], 'r:')\n",
    "plt.plot([0, 1], [x - 1.36 / np.sqrt(Nlow) for x in [0, 1]], 'r:')\n",
    "plt.plot(Femp, Fmodel)\n",
    "plt.axis([0, 1, 0, 1])         \n",
    "plt.xlabel('Model CDF')\n",
    "plt.ylabel('Empirical CDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe0c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_estimate = pm.find_MAP(model=model)\n",
    "del map_estimate['w_simplex__']\n",
    "del map_estimate['mu1_interval__']\n",
    "del map_estimate['lam1_interval__']\n",
    "del map_estimate['mu2_interval__']\n",
    "del map_estimate['sigma2_interval__']\n",
    "del map_estimate['mu3_interval__']\n",
    "del map_estimate['sigma3_interval__']\n",
    "\n",
    "map_estimate['w1'] = map_estimate['w'][0]\n",
    "map_estimate['w2'] = map_estimate['w'][1]\n",
    "map_estimate['w3'] = map_estimate['w'][2]\n",
    "\n",
    "del map_estimate['w']\n",
    "\n",
    "\n",
    "map_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e8380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012ee18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame()\n",
    "list_neurons = adj_neur\n",
    "counter=0\n",
    "print('Original number of neurons: ',len(list_neurons))\n",
    "for neuron in list_neurons:\n",
    "    neuron=neuron[neuron>0*10000]\n",
    "    neuron=neuron[neuron<200*10000]\n",
    "    print('  Neuron with ',neuron.shape[0],'spikes')\n",
    "    if neuron.shape[0]>1000:\n",
    "\n",
    "        counter+=1\n",
    "    else:\n",
    "        print('    Excluded neuron with n spikes = ',neuron.shape[0])\n",
    "        continue\n",
    "\n",
    "    ISI_healthy = np.diff(neuron)/10000\n",
    "\n",
    "\n",
    "    map_estimate = Bayesian_mixture_model(ISI_healthy)\n",
    "\n",
    "    df = pd.DataFrame.from_dict(map_estimate,orient='index')\n",
    "    dataframe = pd.concat([dataframe,df],axis = 1)\n",
    "print('Final number of neurons: ',counter)\n",
    "print('Target = ',target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088dafb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = dataframe.T\n",
    "final.to_csv('Data after PP/DataAfter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f05783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d895b87",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f67edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_visualizer(trials_obj,n_models,choice=False,**choice_var):\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    performance = [1-t['result']['loss'] for t in trials_obj.trials]\n",
    "    \n",
    "    \n",
    "    hyperparam= list(trials_obj.trials[0]['misc']['vals'].keys())\n",
    "    \n",
    "    values_dict ={}\n",
    "    \n",
    "    for i in hyperparam:\n",
    "        \n",
    "        values_dict[i]=[]\n",
    "        \n",
    "        for j in trials_obj.trials:\n",
    "            \n",
    "            if(len(j['misc']['vals'][i])==0):\n",
    "                \n",
    "                values_dict[i].append(np.NaN)\n",
    "                \n",
    "            else:\n",
    "            \n",
    "                values_dict[i].append(j['misc']['vals'][i][0])\n",
    "                \n",
    "    out = pd.DataFrame.from_dict(values_dict)\n",
    "    \n",
    "    out['performance'] = performance\n",
    "    \n",
    "    out=out.sort_values(by=['performance'])\n",
    "    \n",
    "    \n",
    "    if choice:\n",
    "        \n",
    "        for i in list(choice_var.keys()):\n",
    "        \n",
    "            for j,_ in enumerate(choice_var[i]):\n",
    "        \n",
    "                out[i]=out[i].replace(j,choice_var[i][j])\n",
    "    \n",
    "    return out.tail(n_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Data after PP/Data')\n",
    "dataset = dataset.drop(['Unnamed: 0'],axis=1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bee329",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
