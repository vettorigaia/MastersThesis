{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc67d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pi√π canali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9107b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NewLibraryENG import *\n",
    "from tqdm.notebook import tqdm\n",
    "import sklearn.preprocessing as ps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from random import randint\n",
    "from fastdtw import fastdtw\n",
    "import copy\n",
    "import pymc as pm\n",
    "#name_data = '2018-11-27T10-29-42POP 2 BL .h5'\n",
    "#name_data = '2018-11-27T12-03-02POP 2 stimulation.h5'\n",
    "#name_data='2018-11-27T10-56-39MiP5 KA stimulation.h5'\n",
    "#name_data='2018-11-27T11-24-28MiP3 stimulation.h5'\n",
    "#name_data='2018-11-27T10-40-53POP 3 BL .h5'\n",
    "#name_data='2019-01-23T11-05-52MIP3 health cortical .h5'\n",
    "#name_data='2019-01-23T15-49-43MEA2 healthy cortical .h5'\n",
    "#name_data='2019-01-23T16-22-47Pop3 healthy cortical .h5'\n",
    "name_data='2019-01-23T16-06-32Pop1 healthy cortical .h5'\n",
    "\n",
    "complete_string='/Users/Gaia_1/Desktop/h5files/'+name_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8597abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h5py.File(complete_string,'r')\n",
    "\n",
    "data_readings = data['Data']['Recording_0']['AnalogStream']['Stream_0']['ChannelData'][()]\n",
    "info = data['Data']['Recording_0']['AnalogStream']['Stream_0']['InfoChannel'][()]\n",
    "info_table = pd.DataFrame(info, columns = list(info.dtype.fields.keys()))\n",
    "labels = info_table['Label']\n",
    "readings = pd.DataFrame(data = data_readings.transpose(), columns = labels)\n",
    "fs = 10000 #Sampling Frequency\n",
    "print(readings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c4b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "inizio=0\n",
    "#len_data=810000 #192 secondi\n",
    "len_data=len(readings)\n",
    "prova=readings.iloc[inizio:len_data, 10:17]\n",
    "prova=prova.drop([b'Ref'],axis=1)\n",
    "ref=readings[b'Ref']\n",
    "ref=ref[inizio:len_data]\n",
    "\n",
    "print(prova.shape,ref.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cd53a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prova_rows = range(prova.shape[0])\n",
    "filt_prova = pd.DataFrame(data = 0, columns=prova.columns, index=prova_rows, dtype = \"float32\")\n",
    "lowcut = 300\n",
    "highcut = 3000\n",
    "fs=10000\n",
    "order=8\n",
    "b,a=butter_bandpass(lowcut,highcut,fs,order=order)\n",
    "filt_ref=filtfilt(b,a,ref)\n",
    "#ref_df = pd.DataFrame({b'Ref': filt_ref})\n",
    "for x in tqdm(range(prova.shape[1])):\n",
    "    filt_prova.values[:,x] = scipy.signal.filtfilt(b, a, prova.values[:,x])\n",
    "for electrode in prova.columns:\n",
    "    filt_prova[electrode] = filt_prova[electrode] - filt_ref\n",
    "#filt_prova = pd.concat([filt_prova, ref_df], axis=1)\n",
    "prova=filt_prova\n",
    "prova.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d216ef31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eed210bb",
   "metadata": {},
   "source": [
    "# Spike detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f7951",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ind=[]\n",
    "neg_ind=[]\n",
    "for electrode in tqdm(prova.columns):\n",
    "    channel=prova[electrode]\n",
    "    pos, neg=find_all_spikes(channel)\n",
    "    pos_ind.append(pos)\n",
    "    neg_ind.append(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac758d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b565d61",
   "metadata": {},
   "source": [
    "BL: window 3000 (threshold 4 MAD) firing 18    \n",
    "BL: window 300 (thresh 3), firing 89    \n",
    "KA: window 3000 (thresh 3), firing 94    \n",
    "KA: window 3000 (thresh 4), firing 29    \n",
    "KA: window 300, (thresh 4) firing 39   \n",
    "KA: window 300, (thresh 3) firing 108   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ec8cc4",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(30, 15))\n",
    "plt.plot(prova, label='Signal Data')\n",
    "plt.scatter(pos, [prova[i] for i in pos], c='red', marker='o', label='Local Maxima')\n",
    "plt.scatter(neg, [prova[i] for i in neg], c='green', marker='o', label='Local Minima')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Signal Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Signal Data with Detected Spikes')\n",
    "#plt.axis([0,3000,-5,5])\n",
    "#plt.savefig('spikes1.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddba0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b355436f",
   "metadata": {},
   "source": [
    "minima,maxima=RMM(prova)\n",
    "print(len(maxima))\n",
    "#segnale BASELINE: firing rate=70 (spikes 26148)\n",
    "#segnale Stimulation: firing rate=69 (spikes 32980)\n",
    "#segnale KA stimulation: firing rate=81 (spikes 47860)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a7067",
   "metadata": {},
   "source": [
    "minima,maxima=find_spikes(prova)\n",
    "len(maxima)\n",
    "#segnale BASELINE: firing rate=27 (spikes 10276)\n",
    "#segnale Stimulation: firing rate=27 (spikes 13198)\n",
    "#segnale KA stimulation: firing rate=32 (spikes 19178)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5256bf0b",
   "metadata": {},
   "source": [
    "minima,maxima=find_spikes_with_memory(prova)\n",
    "len(maxima)\n",
    "#segnale BASELINE: firing rate=25 (spikes 9270)\n",
    "#segnale Stimulation: firing rate=22 (spikes 10579)\n",
    "#segnale KA stimulation: firing rate=8 (spikes 5054)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76991121",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(30, 15))\n",
    "plt.plot(prova, label='Signal Data')\n",
    "plt.scatter(minima, [prova[i] for i in minima], c='red', marker='o', label='Local Minima')\n",
    "plt.scatter(maxima, [prova[i] for i in maxima], c='green', marker='x', label='Local maxima')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Signal Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Signal Data with Detected Spikes')\n",
    "#plt.axis([0,30000,-5,5])\n",
    "#plt.savefig('spikes2.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8f5432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc55e4f8",
   "metadata": {},
   "source": [
    "# Cutouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead6842",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pos_cut=[]\n",
    "neg_cut=[]\n",
    "n_pos=[]\n",
    "n_neg=[]\n",
    "\n",
    "for i,electrode in enumerate(tqdm(prova.columns)):\n",
    "    pos=pos_ind[i]\n",
    "    neg=neg_ind[i]\n",
    "    channel=prova[electrode]\n",
    "    pos_cut1,n_pos1, neg_cut1,n_neg1 = cut(pos,neg,channel)\n",
    "    pos_cut.append(pos_cut1)\n",
    "    neg_cut.append(neg_cut1)\n",
    "    n_pos.append(n_pos1)\n",
    "    n_neg.append(n_neg1)\n",
    "#savedp = copy.deepcopy(pos_cut)\n",
    "#savedn = copy.deepcopy(neg_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15977543",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (tqdm(range(len(pos_cut)))):\n",
    "    pos_cut[i]=mask_cuts(pos_cut[i])\n",
    "    neg_cut[i]= mask_cuts(neg_cut[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e396dc0",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "x=randint(1,len(pos_cut)-1)\n",
    "y=randint(1,len(pos_cut[x])-1)\n",
    "\n",
    "plt.plot(savedp[x][y])\n",
    "plt.plot(pos_cut[x][y])\n",
    "plt.show()\n",
    "#plt.plot(savedn[x])\n",
    "#plt.plot(neg_cut[x])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fa2e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaabeff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dba03b7",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "pca = PCA()\n",
    "pca.fit(pos_cut)\n",
    "explained_variances = pca.explained_variance_ratio_\n",
    "explained_variance_df = pd.DataFrame(data={'Explained Variance': explained_variances},\n",
    "                                     index=range(1, len(explained_variances) + 1))\n",
    "explained_variance_df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67be79a",
   "metadata": {},
   "source": [
    "cumulative_explained_variance = np.cumsum(explained_variances)\n",
    "cumulative_explained_variance_df = pd.DataFrame(data={'Cumulative Explained Variance': cumulative_explained_variance},\n",
    "                                                index=range(1, len(cumulative_explained_variance) + 1))\n",
    "cumulative_explained_variance_df.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ef327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd0ea887",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba86cd0",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "final_data_pos=[]\n",
    "for channel in (tqdm(range(len(pos_cut)))):\n",
    "    channel_clusters= hdbscan_clustering(pos_cut[channel],n_pos[channel],prova.iloc[:,channel])\n",
    "    final_data_pos.append(channel_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1668da9d",
   "metadata": {},
   "source": [
    "BL (window 3000, thresh 4) (less function) fuzzy (1.8, 4, 3.99)   \n",
    "BL (window 300) (less function) fuzzy (19, 18, 9)   \n",
    "BL (window 300) (less function) dbscan (30, 9)   \n",
    "BL (window 300) (bit less function std) fuzzy (8.9, 18.2, 17.8)   \n",
    "BL (window 300) (more cut function) fuzzy (8.9, 17.7, 18.3)   \n",
    "BL (window 300) (more cut function) dbscan (29, 6)   \n",
    "BL (less cut function) fuzzy: (15, 8 ,15)   \n",
    "\n",
    "KA (window 300, thresh 4) (less function) fuzzy (3.8, 4, 1.9)   \n",
    "KA (window 3000, thresh 4) (less function) fuzzy (2.6, 1.2, 2.8)   \n",
    "KA stimualtion 3 clusters fuzzy: (13, 6, 12)   \n",
    "KA stim (window 300) (new cut function) (1.17,2.55,2.37)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb7976b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "final_data_neg=[]\n",
    "for channel in (tqdm(range(len(neg_cut)))):\n",
    "    channel_clusters= hdbscan_clustering(neg_cut[channel],n_neg[channel],data)\n",
    "    final_data_neg.append(channel_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da37f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# togliere dal best score il DB score e usare solo il silhouette score ma su 15 prove\n",
    "# fare scrematura una volta formati i clusters, togliendo gli spike con distanza DTW sopra soglia\n",
    "# provare anche DTW tra medie di cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5882bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allinfo=[]\n",
    "final_data_pos=[]\n",
    "for channel in (tqdm(range(len(pos_cut)))):\n",
    "    channel_clusters,info=clus(pos_cut[channel],'kmeans',n_pos[channel],prova.iloc[:,channel])\n",
    "    final_data_pos.append(channel_clusters)\n",
    "    allinfo.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ab0c17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_data_neg=[]\n",
    "print(name_data)\n",
    "for channel in (tqdm(range(len(neg_cut)))):\n",
    "    channel_clusters,info=clus(neg_cut[channel],'kmeans',n_neg[channel],prova.iloc[:,channel])\n",
    "    final_data_neg.append(channel_clusters)\n",
    "    allinfo.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f658ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustersdtw(cut,labels,unique_labels):\n",
    "    u_l=copy.deepcopy(unique_labels)\n",
    "    labs=unique_labels\n",
    "    clusters=[]\n",
    "    list0=[]\n",
    "    list0.append(0)\n",
    "    clusters.append(list0)\n",
    "    for i, first_cluster_loop in enumerate(u_l):\n",
    "        spike1=np.mean(cut[labels==first_cluster_loop],axis=0)\n",
    "        check=0\n",
    "        for i in range(len(clusters)):\n",
    "            if first_cluster_loop in clusters[i]:\n",
    "                check=1\n",
    "        if check==0:\n",
    "            list0=[]\n",
    "            list0.append(first_cluster_loop)\n",
    "            clusters.append(list0)\n",
    "        for j, second_cluster_loop in enumerate(u_l[i+1:]):\n",
    "            spike2=np.mean(cut[labels==second_cluster_loop],axis=0)\n",
    "            distance,path=fastdtw(spike1, spike2)\n",
    "            if distance<=4 and first_cluster_loop!=second_cluster_loop:\n",
    "                for arr in clusters:\n",
    "                    if first_cluster_loop in arr and second_cluster_loop not in arr:\n",
    "                        arr.append(second_cluster_loop)\n",
    "                        ind=np.where(labs==second_cluster_loop)\n",
    "                        labs=np.delete(labs,ind)\n",
    "                    elif first_cluster_loop not in arr and second_cluster_loop in arr:\n",
    "                        arr.append(first_cluster_loop)\n",
    "                        ind=np.where(labs==first_cluster_loop)\n",
    "                        labs=np.delete(labs,ind)                    \n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbad9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters=clustersdtw(cut,labels,unique_labels)\n",
    "clusters\n",
    "clus=[]\n",
    "cluster_data=[]\n",
    "for i in range(len(clusters)):\n",
    "    clus.append(i)\n",
    "    clusterings=[]\n",
    "    for j in range(len(clusters[i])):\n",
    "        clusterings.extend(cut[labels==clusters[i][j]])\n",
    "    cluster_data.append(clusterings)\n",
    "print(clusters,clus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2df55b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(cluster_data)):\n",
    "    plt.plot(np.array(cluster_data[i]).transpose())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cddbdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77036ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    firings=np.zeros(len(unique_labels))\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 12))\n",
    "\n",
    "    # Iterate over unique cluster labels\n",
    "    for i, cluster_label in enumerate(unique_labels):\n",
    "        # Extract data points for the current cluster\n",
    "        cluster_data = cut[labels == cluster_label]\n",
    "        firings[i]=len(cluster_data)*10000/len_data\n",
    "        \n",
    "        # Plot the individual cluster data\n",
    "        if len(unique_labels)<=2:\n",
    "            size1=len(unique_labels)\n",
    "            size2=1\n",
    "        elif len(unique_labels)<=5:\n",
    "            size1 = math.ceil(len(unique_labels)/2)\n",
    "            size2=size1\n",
    "        elif len(unique_labels)<=8:\n",
    "            size1 = 3\n",
    "            size2=math.ceil(len(unique_labels)/size1)\n",
    "        else:\n",
    "            size1=6\n",
    "            size2=math.ceil(len(unique_labels)/size1)\n",
    "        plt.subplot(size1,size2, i + 1)\n",
    "        plt.plot(cluster_data.transpose(), alpha=0.5)  # Use alpha for transparency\n",
    "        #print(cluster_data)\n",
    "        plt.title(f'Cluster {cluster_label} \\n numerosity: {len(cluster_data)}')\n",
    "        plt.xlabel('Time [ms]')\n",
    "        plt.ylabel('Signal Amplitude')\n",
    "\n",
    "        # Plot the average waveform\n",
    "        mean_wave = np.mean(cluster_data, axis=0)\n",
    "        info.append(f'mean clus{cluster_label}')\n",
    "        info.append(mean_wave)\n",
    "        std_wave = np.std(cluster_data, axis=0)\n",
    "        plt.errorbar(range(mean_wave.shape[0]), mean_wave, yerr=std_wave, color='black', linewidth=2, label='Avg. Waveform')\n",
    "        plt.legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    mean_firing=np.mean(firings)\n",
    "    std_firing=np.std(firings)\n",
    "    firing_threshold=mean_firing-std_firing\n",
    "    print('firing rate threshold: ',firing_threshold)\n",
    "    info.append('firing threshold')\n",
    "    info.append(firing_threshold)\n",
    "    info.append('mean firing')\n",
    "    info.append(mean_firing)\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    plt.show()\n",
    "    spike_list=np.array(spike_list)\n",
    "    for i in range(0,len(unique_labels)):\n",
    "        ul=spike_list[labels==i]\n",
    "        temporary_data.append(ul)\n",
    "        fr=len(temporary_data[i])*10000/len_data\n",
    "        if i != -1 and fr>firing_threshold:\n",
    "            final_data.append(ul)\n",
    "        plt.subplot(size1, size2, i + 1)\n",
    "        plt.hist(np.diff(ul), bins=100, density=True, alpha=0.5, color='blue', edgecolor='black')\n",
    "        plt.title(f'ISI: Cluster {i} \\n numerosity: {len(temporary_data[i])}, \\n firing rate: {format(len(temporary_data[i])*10000/len_data, \".3f\")}')\n",
    "    plt.subplots_adjust(hspace=2.5)\n",
    "    plt.show()\n",
    "    del(unique_labels)\n",
    "    return final_data, info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2b9409",
   "metadata": {},
   "source": [
    "BL (less cut function) (window 3000, thresh4) fuzzy: (3.5, 3.5, 1.6) silhouette: 0.231    \n",
    "BL (less cut function) (window 300) fuzzy: (17, 15, 6) silhouette: 0.215    \n",
    "BL (more cut function) (window 300) fuzzy: (15, 16, 7) silhouette: 0.218    \n",
    "BL (less cut function) fuzzy: (13, 13, 6) silhouette: 0.226    \n",
    "\n",
    "KA (less cut function) (window 300, thresh4) fuzzy: (1.9, 1.12, 1.9) silhouette: 0.229   \n",
    "KA (less cut function) (window 3000, thresh4) fuzzy: (1.4, 0.89, 1.4) silhouette: 0.223    \n",
    "KA stimulation 3 clusters fuzzy: (3.9, 3.7, 2) silhouette: 0.214    \n",
    "KA stimulation (more cut function) (window 3000) fuzzy: (2, 3.9, 3.7) silhouette: 0.214    \n",
    "KA stimulation (more cut function) (window 300) fuzzy (4.5, 4.4, 2.2) silhouette: 0.204    \n",
    "KA stimulation (more cut function) (window 300) dbscan (10.8,10.8)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a916b18b",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad239a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = []\n",
    "for electrode in final_data_pos:\n",
    "    for neuron in electrode:\n",
    "        neurons.append(neuron)\n",
    "len(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4785de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for neuron in final_data_neg:\n",
    "    for neuron in electrode:\n",
    "        neurons.append(neuron)\n",
    "len(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6b2842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adj_neur=[]\n",
    "counter = 0\n",
    "max_len=0\n",
    "\n",
    "for neu in neurons:\n",
    "    print('counter: ',counter,neu.shape[0])\n",
    "    if neu.shape[0]>max_len:\n",
    "        max_len=neu.shape[0]\n",
    "    counter+=1\n",
    "for neuron in neurons:\n",
    "    if neuron.shape[0]<=max_len:\n",
    "        diff = max_len-neuron.shape[0]\n",
    "        adj_neur.append(np.concatenate((neuron,np.zeros([diff]))))\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37fb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data = 'After'+name_data+'.txt'\n",
    "print(name_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac48f07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(save_data,adj_neur, delimiter=', ', fmt='%12.8f')\n",
    "np.savetxt(\"/Users/Gaia_1/Desktop/tesi/Data after SS/%s.txt\" % save_data,adj_neur, delimiter=', ', fmt='%12.8f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72247e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=randint(0,len(adj_neur))\n",
    "print('neur: ',x)\n",
    "data_healthy=adj_neur[x]\n",
    "ISI_healthy = np.diff(data_healthy)/10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac710f3",
   "metadata": {},
   "source": [
    "## Point Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4112e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd9e251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_estimate = Bayesian_mixture_model(ISI_healthy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616df556",
   "metadata": {},
   "source": [
    "#with model:\n",
    "#    ppc_trace = pm.sample_posterior_predictive(trace,model=model)\n",
    "\n",
    "bins = np.arange(0, .5, 1e-3) \n",
    "plt.figure (figsize=(14,10))\n",
    "\n",
    "hist = np.histogram(ppc_trace['posterior_predictive']['like'].values,bins=bins)\n",
    "#plt.axis([0,0.3,0,160])\n",
    "a= plt.hist(ISI_healthy,bins)\n",
    "plt.plot(hist[1][:-1],hist[0]/1000,linewidth=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79200f",
   "metadata": {},
   "source": [
    "lista_samples=[]\n",
    "for i in list(ppc_trace['posterior_predictive']['like'].values):\n",
    "    lista_samples.extend(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a18e55",
   "metadata": {},
   "source": [
    "counts, _ = np.histogram(ISI_healthy, bins) \n",
    "prob_emp = counts / np.sum(counts)\n",
    "counts, _ = np.histogram(lista_samples, bins) \n",
    "prob_model = counts / np.sum(counts)\n",
    "\n",
    "Femp = np.cumsum(prob_emp)           \n",
    "Fmodel = np.cumsum(prob_model)          \n",
    "plt.figure()\n",
    "plt.plot(bins[:-1], Femp)                \n",
    "plt.plot(bins[:-1], Fmodel, 'r')       \n",
    "#plt.xlim([0, 0.2])                  \n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('CDF')\n",
    "plt.legend(['Empirical','Model'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8830c596",
   "metadata": {},
   "source": [
    "plt.figure()\n",
    "Nlow = len(ISI_healthy)  \n",
    "# Plot the confidence bounds\n",
    "plt.plot([0, 1], [x + 1.36 / np.sqrt(Nlow) for x in [0, 1]], 'r:')\n",
    "plt.plot([0, 1], [x - 1.36 / np.sqrt(Nlow) for x in [0, 1]], 'r:')\n",
    "plt.plot(Femp, Fmodel)\n",
    "plt.axis([0, 1, 0, 1])         \n",
    "plt.xlabel('Model CDF')\n",
    "plt.ylabel('Empirical CDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e8380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012ee18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame()\n",
    "list_neurons = adj_neur\n",
    "counter=0\n",
    "print('Original number of neurons: ',len(list_neurons))\n",
    "for neuron in list_neurons:\n",
    "    neuron=neuron[neuron>0*10000]\n",
    "    neuron=neuron[neuron<200*10000]\n",
    "    print('  Neuron with ',neuron.shape[0],'spikes')\n",
    "    if neuron.shape[0]>1000:\n",
    "\n",
    "        counter+=1\n",
    "    else:\n",
    "        print('    Excluded neuron with n spikes = ',neuron.shape[0])\n",
    "        continue\n",
    "\n",
    "    ISI_healthy = np.diff(neuron)/10000\n",
    "\n",
    "\n",
    "    map_estimate = Bayesian_mixture_model(ISI_healthy)\n",
    "    if 'Healthy' in net:\n",
    "        print('target Healthy')\n",
    "        map_estimate['Target']=0\n",
    "\n",
    "    elif 'healthy' in net:\n",
    "        print('target healthy')\n",
    "        map_estimate['Target']=0\n",
    "\n",
    "    elif 'health' in net:\n",
    "        print('target health')\n",
    "        map_estimate['Target']=0\n",
    "\n",
    "    else:\n",
    "        print('target pathological')\n",
    "        map_estimate['Target']=1\n",
    "\n",
    "    if 'KA' in net:\n",
    "        map_estimate['Stimulation']=1\n",
    "\n",
    "    elif 'stimulation' in net:\n",
    "        map_estimate['Stimulation']=1\n",
    "    else:\n",
    "        map_estimate['Stimulation']=0\n",
    "\n",
    "    df = pd.DataFrame.from_dict(map_estimate,orient='index')\n",
    "    dataframe = pd.concat([dataframe,df],axis = 1)\n",
    "print('Final number of neurons: ',counter)\n",
    "print('Target = ',target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088dafb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = dataframe.T\n",
    "final.to_csv('Data after PP/DataAfter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f05783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d895b87",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f67edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_visualizer(trials_obj,n_models,choice=False,**choice_var):\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    performance = [1-t['result']['loss'] for t in trials_obj.trials]\n",
    "    \n",
    "    \n",
    "    hyperparam= list(trials_obj.trials[0]['misc']['vals'].keys())\n",
    "    \n",
    "    values_dict ={}\n",
    "    \n",
    "    for i in hyperparam:\n",
    "        \n",
    "        values_dict[i]=[]\n",
    "        \n",
    "        for j in trials_obj.trials:\n",
    "            \n",
    "            if(len(j['misc']['vals'][i])==0):\n",
    "                \n",
    "                values_dict[i].append(np.NaN)\n",
    "                \n",
    "            else:\n",
    "            \n",
    "                values_dict[i].append(j['misc']['vals'][i][0])\n",
    "                \n",
    "    out = pd.DataFrame.from_dict(values_dict)\n",
    "    \n",
    "    out['performance'] = performance\n",
    "    \n",
    "    out=out.sort_values(by=['performance'])\n",
    "    \n",
    "    \n",
    "    if choice:\n",
    "        \n",
    "        for i in list(choice_var.keys()):\n",
    "        \n",
    "            for j,_ in enumerate(choice_var[i]):\n",
    "        \n",
    "                out[i]=out[i].replace(j,choice_var[i][j])\n",
    "    \n",
    "    return out.tail(n_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Data after PP/Data')\n",
    "dataset = dataset.drop(['Unnamed: 0'],axis=1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bee329",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
