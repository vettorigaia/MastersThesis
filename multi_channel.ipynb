{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc67d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#piÃ¹ canali\n",
    "#valutare se settare i margini dei firing rates tra 0.16-2Hz come nel paper\n",
    "#derivata seconda su waveform papers\n",
    "# un file con bl e stimulato (clustering su tutto e divisione in due classi in base a indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a3e829",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from NewLibraryENGcopia import *\n",
    "import glob\n",
    "final=[]\n",
    "output_path='/Users/Gaia_1/Desktop/tesi/Data after SS'\n",
    "list_dir=glob.glob(output_path+\"/*\")\n",
    "#file=list_dir[0]\n",
    "for file in list_dir:\n",
    "    target=1\n",
    "    stim=0\n",
    "    if 'health' in file:\n",
    "        target=0\n",
    "    if 'stimulation' in file:\n",
    "        stim=1\n",
    "    list_neurons = np.genfromtxt(file, delimiter=',')\n",
    "    df=this_poiproc(list_neurons,target,stim)\n",
    "    final.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650ab354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac7e79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c921d485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffe5e583",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f69801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def this_single_poiproc(neurons,target,stim,which):\n",
    "neurons=np.genfromtxt(file, delimiter=',')\n",
    "target=0\n",
    "stim=0\n",
    "which=5\n",
    "from scipy.stats import ks_2samp\n",
    "dataframe = pd.DataFrame()\n",
    "#counter_net=1\n",
    "counter=0\n",
    "#for net in list_dir_ok:\n",
    "#print(counter_net,') ',net)\n",
    "#counter_net+=1\n",
    "list_neurons = neurons #np.genfromtxt(net, delimiter=',')\n",
    "counter=0\n",
    "print('Original number of neurons: ',len(list_neurons))\n",
    "#for neuron in tqdm(list_neurons):\n",
    "neuron=list_neurons[which]\n",
    "neuron=neuron[neuron>0*10000]\n",
    "neuron=neuron[neuron<200*10000]\n",
    "print('  Neuron with ',neuron.shape[0],'spikes')\n",
    "if neuron.shape[0]>1000:\n",
    "\n",
    "    counter+=1\n",
    "    ISI_healthy = np.diff(neuron)/10000\n",
    "    map_estimate = this_Bayesian_mixture_model(ISI_healthy)\n",
    "    map_estimate['Target']=target\n",
    "    map_estimate['Stimulation']=stim\n",
    "    df = pd.DataFrame.from_dict(map_estimate,orient='index')\n",
    "    dataframe = pd.concat([dataframe,df],axis = 1)\n",
    "    print('Final number of neurons: ',counter)\n",
    "    print('Target = ',target)\n",
    "    #ks_2samp(lista_samples,ISI_healthy,mode = 'asymp')\n",
    "\n",
    "else:\n",
    "    print('    Excluded neuron with n spikes = ',neuron.shape[0])\n",
    "\n",
    "#return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37bc36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def this_Bayesian_mixture_model(ISI_data):\n",
    "    import scipy.stats as st\n",
    "    with pm.Model() as model:\n",
    "        ##### WALD DISTRIBUTION (INVERSE GAUSSIAN)\n",
    "        mu1 = pm.Uniform('mu1',lower=0.001,upper=0.02)\n",
    "        lam1 = pm.Uniform('lam1',lower=0.001,upper=0.04)\n",
    "        obs1 = pm.Wald.dist(mu=mu1,lam=lam1)\n",
    "\n",
    "\n",
    "        mu2 = pm.Uniform('mu2',lower=0.02,upper=0.04)\n",
    "        sigma2 = pm.Uniform('sigma2',lower=0.01,upper=0.7)\n",
    "        obs2 = pm.TruncatedNormal.dist(mu=mu2, sigma=sigma2, lower=0.0)\n",
    "\n",
    "        mu3 = pm.Uniform('mu3',lower=0.04,upper=0.6)\n",
    "        sigma3 = pm.Uniform('sigma3',lower=0.01,upper=0.7)\n",
    "        obs3 = pm.TruncatedNormal.dist(mu=mu3, sigma=sigma3, lower=0.0)\n",
    "        \n",
    "        w = pm.Dirichlet('w', a=np.array([1., 1., 1.]))\n",
    "        like = pm.Mixture('like', w=w, comp_dists = [obs1, obs2, obs3], observed=ISI_data)\n",
    "        '''\n",
    "        if counter==9:\n",
    "            step = pm.NUTS(target_accept=0.9)\n",
    "            trace = pm.sample(step=step,draws=1000,chains=1,tune=1000,cores=4)\n",
    "            ppc_trace = pm.sample_posterior_predictive(trace,model=model)\n",
    "            bins = np.arange(0, .5, 1e-3) \n",
    "            plt.figure (figsize=(14,10))\n",
    "            hist = np.histogram(ppc_trace['posterior_predictive']['like'].values,bins=bins)\n",
    "            #plt.axis([-0.01,0.13,0,160])\n",
    "            a= plt.hist(ISI_data,bins)\n",
    "            plt.plot(hist[1][:-1],hist[0]/1000,linewidth=3)\n",
    "            plt.show()\n",
    "        '''\n",
    "\n",
    "    map_estimate = pm.find_MAP(model=model)\n",
    "    '''\n",
    "    {'mu1': array(0.04042722), 'lam1': array(0.02654692), \n",
    "    'mu2': array(1.66044929e-10), 'sigma2': array(0.0001), \n",
    "    'mu3': array(0.1105011), 'sigma3': array(0.10631582), \n",
    "    'w1': 1.0, 'w2': 1.293372623362383e-50, 'w3': 6.251544417193884e-71}\n",
    "    ''' \n",
    "    d= np.linspace(0.00, 1, len(ISI_data))\n",
    "    map_estimate['w1'] = map_estimate['w'][0]\n",
    "    map_estimate['w2'] = map_estimate['w'][1]\n",
    "    map_estimate['w3'] = map_estimate['w'][2]\n",
    "    \n",
    "    mu1=map_estimate['mu1']\n",
    "    mu2=map_estimate['mu2']\n",
    "    mu3=map_estimate['mu3']\n",
    "    lam1=map_estimate['lam1']\n",
    "    sigma2=map_estimate['sigma2']\n",
    "    sigma3=map_estimate['sigma3']\n",
    "    w1=map_estimate['w1']\n",
    "    w2=map_estimate['w2']\n",
    "    w3=map_estimate['w3']       \n",
    "    \n",
    "    pdf = w1*st.invgauss.pdf(d, mu1/lam1, scale = lam1) + w2*st.norm.pdf(d, mu2, sigma2) + w3*st.norm.pdf(d, mu3, sigma3)\n",
    "    bins = np.arange(0, .5, 1e-3) \n",
    "    \n",
    "    plt.hist(ISI_healthy, bins, color='orange', alpha=0.7, label='Histogram',density=True)\n",
    "    plt.plot(d, pdf, color='blue', label='PDF')\n",
    "    #plt.xlim(0, 0.2)\n",
    "    plt.show()\n",
    "\n",
    "    cdf_2gauss = lambda x: w1 * st.invgauss.cdf(x,mu1/lam1, scale = lam1) + w2 * st.norm.cdf(x, mu2, sigma2) + w3*st.norm.cdf(x, mu3, sigma3)\n",
    "    #cdf_2gauss = lambda x: w1 * st.norm.cdf(x, mu1, sigma1) + w2 * st.norm.cdf(x, mu2, sigma2) + w3*st.invgauss.cdf(x,mu3/lam3, scale = lam3)\n",
    "    ks_score=st.ks_1samp(ISI_data[ISI_data>0],  cdf_2gauss, method = 'asymp')\n",
    "    print('ks score: ',ks_score)\n",
    "    \n",
    "    del map_estimate['w_simplex__']\n",
    "    del map_estimate['mu1_interval__']\n",
    "    del map_estimate['lam1_interval__']\n",
    "    del map_estimate['mu2_interval__']\n",
    "    del map_estimate['sigma2_interval__']\n",
    "    del map_estimate['mu3_interval__']\n",
    "    del map_estimate['sigma3_interval__']\n",
    "    \n",
    "    \n",
    "    del map_estimate['w']\n",
    "\n",
    "    print(map_estimate)\n",
    "    return map_estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda7b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def this_poiproc(neurons,target,stim):\n",
    "    from scipy.stats import ks_2samp\n",
    "    dataframe = pd.DataFrame()\n",
    "    #counter_net=1\n",
    "    counter=0\n",
    "    #for net in list_dir_ok:\n",
    "    #print(counter_net,') ',net)\n",
    "    #counter_net+=1\n",
    "    list_neurons = neurons #np.genfromtxt(net, delimiter=',')\n",
    "    counter=0\n",
    "    print('Original number of neurons: ',len(list_neurons))\n",
    "    for neuron in tqdm(list_neurons):\n",
    "        neuron=neuron[neuron>0*10000]\n",
    "        neuron=neuron[neuron<200*10000]\n",
    "        print('  Neuron with ',neuron.shape[0],'spikes')\n",
    "        if neuron.shape[0]>1000:\n",
    "            \n",
    "            counter+=1\n",
    "        else:\n",
    "            print('    Excluded neuron with n spikes = ',neuron.shape[0])\n",
    "            continue\n",
    "        \n",
    "        ISI_healthy = np.diff(neuron)/10000\n",
    "        map_estimate = this_Bayesian_mixture_model(ISI_healthy)\n",
    "        map_estimate['Target']=target\n",
    "        map_estimate['Stimulation']=stim\n",
    "        df = pd.DataFrame.from_dict(map_estimate,orient='index')\n",
    "        dataframe = pd.concat([dataframe,df],axis = 1)\n",
    "    print('Final number of neurons: ',counter)\n",
    "    print('Target = ',target)\n",
    "    #ks_2samp(lista_samples,ISI_healthy,mode = 'asymp')\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38272d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9732ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a973411e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9107b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NewLibraryENGcopia import *\n",
    "from tqdm.notebook import tqdm\n",
    "import sklearn.preprocessing as ps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from random import randint\n",
    "from fastdtw import fastdtw\n",
    "import copy\n",
    "import pymc as pm\n",
    "#name_data = '2018-11-27T10-29-42POP 2 BL .h5'\n",
    "#name_data = '2018-11-27T12-03-02POP 2 stimulation.h5'\n",
    "#name_data='2018-11-27T10-56-39MiP5 KA stimulation.h5'\n",
    "#name_data='2018-11-27T11-24-28MiP3 stimulation.h5'\n",
    "#name_data='2018-11-27T10-40-53POP 3 BL .h5'\n",
    "#name_data='2019-01-23T11-05-52MIP3 health cortical .h5'\n",
    "#name_data='2019-01-23T15-49-43MEA2 healthy cortical .h5'\n",
    "#name_data='2019-01-23T16-22-47Pop3 healthy cortical .h5'\n",
    "#name_data='2019-01-23T16-06-32Pop1 healthy cortical .h5'\n",
    "name_data='2019-01-24T16-00-33Pop1 24hour after.h5'\n",
    "\n",
    "complete_string='/Users/Gaia_1/Desktop/allh5files/healthy/healthy 24hrs later/'+name_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d648eee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from NewLibraryENGcopia import *\n",
    "#name_data='2019-01-23T16-06-32Pop1 healthy cortical .h5'\n",
    "complete_string='/Users/Gaia_1/Desktop/allh5filesprova2/2019-01-23T16-06-32Pop1 healthy cortical .h5'\n",
    "name_data = complete_string.split(\"/\")[-1]\n",
    "#neurons=spike_sorting(name_data,complete_string,1,5,1.5)\n",
    "cuts,all_new=this_spike_sorting(name_data,complete_string,1,5,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfdd122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078f545d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_data=this_clus(cuts[0],all_new[0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3747c0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def this_clus(cut,spike_list,data):\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    import numpy as np\n",
    "    scale = StandardScaler()\n",
    "    estratti_norm = scale.fit_transform(cut)\n",
    "    print('\\n______________________________________________________________________________________________________________')\n",
    "    print('Total spikes: ', estratti_norm.shape[0])\n",
    "    n_comp=3\n",
    "    pca = PCA(n_components=n_comp)\n",
    "    transformed = pca.fit_transform(estratti_norm)\n",
    "    spike_list=np.array(spike_list)\n",
    "    kmeans_score=[]\n",
    "    final_data=[]\n",
    "    for n in range (2,4):\n",
    "        model = KMeans(n_clusters=n, init='k-means++', n_init=10, max_iter=400, tol=0.25, verbose=0, random_state=None, copy_x=True,  algorithm='lloyd')\n",
    "        labels = model.fit_predict(transformed)\n",
    "        silhouette_avg = silhouette_score(transformed, labels)\n",
    "        kmeans_score.append(silhouette_avg)\n",
    "    top_clusters_kmeans = kmeans_score.index(max(kmeans_score))+2\n",
    "    if max(kmeans_score)>=0.4:\n",
    "        print(\"\\n\\n\\033[1;31;47mBest cluster in the range 1 to 3: \",top_clusters_kmeans,\", with a silhouette score of: \",max(kmeans_score), \"\\u001b[0m  \\n\\n\")\n",
    "        model = KMeans(n_clusters=top_clusters_kmeans,  init='k-means++', n_init=10, max_iter=400, tol=0.25, verbose=0, random_state=None, copy_x=True,  algorithm='lloyd')\n",
    "        labels = model.fit_predict(transformed)\n",
    "    else:\n",
    "        print('Clustering algorithm detected only one cluster')\n",
    "        labels=np.zeros(len(spike_list),dtype=int)\n",
    "    unique_labels=np.unique(labels)\n",
    "    firings=np.zeros(len(unique_labels))\n",
    "    color=[]\n",
    "    for i in labels:\n",
    "        color.append(plt.rcParams['axes.prop_cycle'].by_key()['color'][i])\n",
    "        if i==-1:\n",
    "            color[i]='k'\n",
    "    for i,cluster_label in enumerate(unique_labels):\n",
    "        cluster_data=cut[labels==cluster_label]\n",
    "        mean_wave=np.mean(cluster_data, axis=0)\n",
    "        std_wave=np.std(cluster_data, axis=0)\n",
    "        distances=np.abs(cluster_data - mean_wave)\n",
    "        distance_threshold=3*std_wave\n",
    "        indices_to_keep=np.all(distances<=distance_threshold,axis=1)\n",
    "        filtered_cluster_data=cluster_data[indices_to_keep]\n",
    "        plotting_data=filtered_cluster_data.transpose()\n",
    "        #firings[i]=len(filtered_cluster_data)*10000/len(data)\n",
    "        plt.subplot(3,1,i+1)\n",
    "        plt.plot(plotting_data,alpha=0.5)\n",
    "        plt.title(f'Cluster {i} \\n numerosity: {len(filtered_cluster_data)}')\n",
    "        plt.xlabel('Time [ms]')\n",
    "        plt.ylabel('Signal Amplitude')\n",
    "        mean_wave = np.mean(filtered_cluster_data, axis=0)\n",
    "        std_wave = np.std(filtered_cluster_data, axis=0)\n",
    "        plt.errorbar(range(mean_wave.shape[0]), mean_wave, yerr=std_wave, color='black', linewidth=2, label='Avg. Waveform')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "        ul=spike_list[labels==i]\n",
    "        ull=ul[indices_to_keep]\n",
    "        final_data.append(ull)\n",
    "        plt.subplot(3, 1, i + 1)\n",
    "        plt.hist(np.diff(ull), bins=100, density=True, alpha=0.5, color='blue', edgecolor='black')\n",
    "        #plt.title(f'ISI: Cluster {i}, \\n firing rate: {format(len(final_data[i])*10000/len(data), \".2f\")} Hz')\n",
    "        plt.show()        \n",
    "    if len(unique_labels)>1:\n",
    "        fig = plt.figure(figsize=(18,8))\n",
    "        ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "        ax.scatter(transformed[:,0], transformed[:,1], transformed[:,2], c=color, alpha=0.8, s=10, marker='.')\n",
    "        ax = fig.add_subplot(1, 2, 2)\n",
    "        for i,cluster_label in enumerate(unique_labels):    \n",
    "            idx=cluster_label==i\n",
    "            color = plt.rcParams['axes.prop_cycle'].by_key()['color'][i]\n",
    "            mean_wave = np.mean(cut[idx,:],axis = 0)\n",
    "            std_wave = np.std(cut[idx,:],axis = 0)\n",
    "            print(mean_wave,type(mean_wave),np.shape(mean_wave))\n",
    "            #ax.errorbar(range(cut[idx,:].shape[1]),mean_wave,yerr = std_wave)\n",
    "            #plt.errorbar(range(mean_wave.shape[0]), mean_wave, yerr=std_wave, c=color)\n",
    "            plt.errorbar(range(mean_wave.shape[1],mean_wave, yerr=std_wave, c=color)\n",
    "            #ax.errorbar(range(mean_wave.shape[0]),mean_wave,yerr = std_wave)\n",
    "\n",
    "        plt.xlabel('Time [0.1ms]')\n",
    "        plt.ylabel('Voltage [\\u03BCV]')\n",
    "        plt.show()    \n",
    "    '''\n",
    "    #Plot average waveform\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    for i in range(len(set(cluster_labels))-1):\n",
    "        idx = cluster_labels == i\n",
    "        color = plt.rcParams['axes.prop_cycle'].by_key()['color'][i]\n",
    "        mean_wave = np.mean(cutouts[idx,:],axis = 0)\n",
    "        std_wave = np.std(cutouts[idx,:],axis = 0)\n",
    "        ax.errorbar(range(cutouts[idx,:].shape[1]),mean_wave,yerr = std_wave)\n",
    "     \n",
    "    plt.xlabel('Time [0.1ms]')\n",
    "    plt.ylabel('Voltage [\\u03BCV]')\n",
    "    plt.show()    \n",
    "    '''      \n",
    "    return final_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c59f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef6944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def this_spike_sorting(name_data,complete_string,abso,coeff,c1):\n",
    "    #file reading:\n",
    "    data = h5py.File(complete_string,'r')\n",
    "    data_readings = data['Data']['Recording_0']['AnalogStream']['Stream_0']['ChannelData'][()]\n",
    "    info = data['Data']['Recording_0']['AnalogStream']['Stream_0']['InfoChannel'][()]\n",
    "    info_table = pd.DataFrame(info, columns = list(info.dtype.fields.keys()))\n",
    "    labels = info_table['Label']\n",
    "    readings = pd.DataFrame(data = data_readings.transpose(), columns = labels)\n",
    "    fs = 10000 #Sampling Frequency\n",
    "    print('data shape: ',readings.shape)\n",
    "    prova=readings.drop([b'Ref'],axis=1)\n",
    "    inizio=0\n",
    "    fine=int(len(readings)/3)\n",
    "    prova=prova.iloc[inizio:fine, :15]\n",
    "    #prova=prova.iloc[:, :10]\n",
    "    ref=readings[b'Ref']\n",
    "    ref=ref[inizio:fine]\n",
    "    #filtering:\n",
    "    prova_rows = range(prova.shape[0])\n",
    "    filt_prova = pd.DataFrame(data = 0, columns=prova.columns, index=prova_rows, dtype = \"float32\")\n",
    "    lowcut = 300\n",
    "    highcut = 3000\n",
    "    fs=10000\n",
    "    order=8\n",
    "    b,a=butter_bandpass(lowcut,highcut,fs,order=order)\n",
    "    filt_ref=filtfilt(b,a,ref)\n",
    "    for x in tqdm(range(prova.shape[1])):\n",
    "        filt_prova.values[:,x] = scipy.signal.filtfilt(b, a, prova.values[:,x])\n",
    "    for electrode in prova.columns:\n",
    "        filt_prova[electrode] = filt_prova[electrode] - filt_ref\n",
    "    prova=filt_prova\n",
    "    #detection:\n",
    "    all_ind=[]\n",
    "    for i,electrode in enumerate(tqdm(prova.columns)):\n",
    "        channel=prova[electrode]\n",
    "        ind=windowed_spike_detection(channel,coeff,abso)\n",
    "        all_ind.append(ind)\n",
    "    #spike extraction:\n",
    "    cut_outs=[]\n",
    "    all_new=[]\n",
    "    for i,electrode in enumerate(tqdm(prova.columns)):\n",
    "        ind=all_ind[i]\n",
    "        channel=prova[electrode]\n",
    "        cut_outs1,all_new1=cut_all(ind,channel,c1)\n",
    "        cut_outs.append(cut_outs1)\n",
    "        all_new.append(all_new1)  \n",
    "    '''\n",
    "    # Clustering:\n",
    "    final_data=[]\n",
    "    for channel in (tqdm(range(len(cut_outs)))):\n",
    "        #channel_clusters1=comparative_clus(cut_outs[channel],all_new[channel],prova.iloc[:,channel])\n",
    "        channel_clusters1=this_clus(cut_outs[channel],all_new[channel],prova.iloc[:,channel])\n",
    "        final_data.append(channel_clusters1)\n",
    "    neurons=[]\n",
    "    for channel in final_data:\n",
    "        for neuron in channel:\n",
    "            neurons.append(neuron)\n",
    "    print(len(neurons),' neurons detected and sorted')\n",
    "    adj_neur=[]\n",
    "    counter = 0\n",
    "    max_len=0\n",
    "    for neuron in neurons:\n",
    "        print('counter: ',counter,neuron.shape[0])\n",
    "        if neuron.shape[0]>max_len:\n",
    "            max_len=neuron.shape[0]\n",
    "        counter+=1\n",
    "    for neuron in neurons:\n",
    "        if neuron.shape[0]<max_len and neuron.shape[0]>=1000:\n",
    "            diff = max_len-neuron.shape[0]\n",
    "            adj_neur.append(np.concatenate((neuron,np.zeros([diff]))))\n",
    "    save_data = 'After'+name_data+'.txt'\n",
    "    np.savetxt(\"/Users/Gaia_1/Desktop/tesi/Data after SS prova/%s.txt\" % save_data,adj_neur, delimiter=', ', fmt='%12.8f')\n",
    "    print(save_data)\n",
    "    '''\n",
    "    return cut_outs,all_new#neurons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88da9b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def this_windowed_spike_detection(data,coeff,abso):\n",
    "    spike_length=30 #3ms\n",
    "    window_length=10000 #1 sec\n",
    "    abs_data=abs(data)\n",
    "    i=0\n",
    "    ind=[]\n",
    "    while i < len(data)+window_length:\n",
    "        abs_window=abs_data[i:i+window_length]\n",
    "        window=data[i:i+window_length]\n",
    "        if abso==0:\n",
    "            thresh=coeff*(scipy.stats.median_abs_deviation(window,scale='normal'))\n",
    "        else:\n",
    "            thresh=coeff*(scipy.stats.median_abs_deviation(abs_window,scale='normal'))\n",
    "        ind1, peaks =find_peaks(abs_window, height=thresh,distance=spike_length)\n",
    "        last=i\n",
    "        if len(ind1):\n",
    "            last=i+ind1[-1]\n",
    "        ind.extend([index + i for index in ind1])\n",
    "        i=last+spike_length\n",
    "    firing_rate=len(ind)*10000/len(data)\n",
    "    print(len(ind), ' spikes detected;  ', 'firing rate: {:.2f}'.format(firing_rate),'Hz')\n",
    "    return ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fcb52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8597abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h5py.File(complete_string,'r')\n",
    "\n",
    "data_readings = data['Data']['Recording_0']['AnalogStream']['Stream_0']['ChannelData'][()]\n",
    "info = data['Data']['Recording_0']['AnalogStream']['Stream_0']['InfoChannel'][()]\n",
    "info_table = pd.DataFrame(info, columns = list(info.dtype.fields.keys()))\n",
    "labels = info_table['Label']\n",
    "readings = pd.DataFrame(data = data_readings.transpose(), columns = labels)\n",
    "fs = 10000 #Sampling Frequency\n",
    "print(readings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c4b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "inizio=0\n",
    "#len_data=810000 #192 secondi\n",
    "len_data=len(readings)\n",
    "prova=readings.iloc[inizio:len_data, 10:27]\n",
    "prova=prova.drop([b'Ref'],axis=1)\n",
    "ref=readings[b'Ref']\n",
    "ref=ref[inizio:len_data]\n",
    "\n",
    "print(prova.shape,ref.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cd53a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prova_rows = range(prova.shape[0])\n",
    "filt_prova = pd.DataFrame(data = 0, columns=prova.columns, index=prova_rows, dtype = \"float32\")\n",
    "lowcut = 300\n",
    "highcut = 3000\n",
    "fs=10000\n",
    "order=8\n",
    "b,a=butter_bandpass(lowcut,highcut,fs,order=order)\n",
    "filt_ref=filtfilt(b,a,ref)\n",
    "#ref_df = pd.DataFrame({b'Ref': filt_ref})\n",
    "for x in tqdm(range(prova.shape[1])):\n",
    "    filt_prova.values[:,x] = scipy.signal.filtfilt(b, a, prova.values[:,x])\n",
    "for electrode in prova.columns:\n",
    "    filt_prova[electrode] = filt_prova[electrode] - filt_ref\n",
    "#filt_prova = pd.concat([filt_prova, ref_df], axis=1)\n",
    "prova=filt_prova\n",
    "prova.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d216ef31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eed210bb",
   "metadata": {},
   "source": [
    "# Spike detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1574e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=[]\n",
    "for i,electrode in tqdm(enumerate(prova.columns)):\n",
    "    threshold.append(4*(scipy.stats.median_abs_deviation(prova[electrode].values)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fc7b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e035fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ind=[]\n",
    "neg_ind=[]\n",
    "for i,electrode in tqdm(enumerate(prova.columns)):\n",
    "    channel=prova[electrode]\n",
    "    thresh=threshold[i]\n",
    "    pos,neg=new_find_all_spikes(channel,thresh)\n",
    "    pos_ind.append(pos)\n",
    "    neg_ind.append(neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785d46b7",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "pos_ind=[]\n",
    "neg_ind=[]\n",
    "for electrode in tqdm(prova.columns):\n",
    "    channel=prova[electrode]\n",
    "    pos, neg=find_all_spikes(channel)\n",
    "    pos_ind.append(pos)\n",
    "    neg_ind.append(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac758d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b565d61",
   "metadata": {},
   "source": [
    "BL: window 3000 (threshold 4 MAD) firing 18    \n",
    "BL: window 300 (thresh 3), firing 89    \n",
    "KA: window 3000 (thresh 3), firing 94    \n",
    "KA: window 3000 (thresh 4), firing 29    \n",
    "KA: window 300, (thresh 4) firing 39   \n",
    "KA: window 300, (thresh 3) firing 108   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ec8cc4",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(30, 15))\n",
    "plt.plot(prova, label='Signal Data')\n",
    "plt.scatter(pos, [prova[i] for i in pos], c='red', marker='o', label='Local Maxima')\n",
    "plt.scatter(neg, [prova[i] for i in neg], c='green', marker='o', label='Local Minima')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Signal Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Signal Data with Detected Spikes')\n",
    "#plt.axis([0,3000,-5,5])\n",
    "#plt.savefig('spikes1.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddba0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b355436f",
   "metadata": {},
   "source": [
    "minima,maxima=RMM(prova)\n",
    "print(len(maxima))\n",
    "#segnale BASELINE: firing rate=70 (spikes 26148)\n",
    "#segnale Stimulation: firing rate=69 (spikes 32980)\n",
    "#segnale KA stimulation: firing rate=81 (spikes 47860)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a7067",
   "metadata": {},
   "source": [
    "minima,maxima=find_spikes(prova)\n",
    "len(maxima)\n",
    "#segnale BASELINE: firing rate=27 (spikes 10276)\n",
    "#segnale Stimulation: firing rate=27 (spikes 13198)\n",
    "#segnale KA stimulation: firing rate=32 (spikes 19178)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5256bf0b",
   "metadata": {},
   "source": [
    "minima,maxima=find_spikes_with_memory(prova)\n",
    "len(maxima)\n",
    "#segnale BASELINE: firing rate=25 (spikes 9270)\n",
    "#segnale Stimulation: firing rate=22 (spikes 10579)\n",
    "#segnale KA stimulation: firing rate=8 (spikes 5054)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76991121",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(30, 15))\n",
    "plt.plot(prova, label='Signal Data')\n",
    "plt.scatter(minima, [prova[i] for i in minima], c='red', marker='o', label='Local Minima')\n",
    "plt.scatter(maxima, [prova[i] for i in maxima], c='green', marker='x', label='Local maxima')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Signal Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Signal Data with Detected Spikes')\n",
    "#plt.axis([0,30000,-5,5])\n",
    "#plt.savefig('spikes2.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8f5432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc55e4f8",
   "metadata": {},
   "source": [
    "# Cutouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead6842",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pos_cut=[]\n",
    "neg_cut=[]\n",
    "n_pos=[]\n",
    "n_neg=[]\n",
    "\n",
    "for i,electrode in enumerate(tqdm(prova.columns)):\n",
    "    pos=pos_ind[i]\n",
    "    neg=neg_ind[i]\n",
    "    channel=prova[electrode]\n",
    "    pos_cut1,n_pos1, neg_cut1,n_neg1 = cut(pos,neg,channel)\n",
    "    pos_cut.append(pos_cut1)\n",
    "    neg_cut.append(neg_cut1)\n",
    "    n_pos.append(n_pos1)\n",
    "    n_neg.append(n_neg1)\n",
    "#savedp = copy.deepcopy(pos_cut)\n",
    "#savedn = copy.deepcopy(neg_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15977543",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (tqdm(range(len(pos_cut)))):\n",
    "    pos_cut[i]=mask_cuts(pos_cut[i])\n",
    "    neg_cut[i]= mask_cuts(neg_cut[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e396dc0",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "x=randint(1,len(pos_cut)-1)\n",
    "y=randint(1,len(pos_cut[x])-1)\n",
    "\n",
    "plt.plot(savedp[x][y])\n",
    "plt.plot(pos_cut[x][y])\n",
    "plt.show()\n",
    "#plt.plot(savedn[x])\n",
    "#plt.plot(neg_cut[x])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fa2e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaabeff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dba03b7",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "pca = PCA()\n",
    "pca.fit(pos_cut)\n",
    "explained_variances = pca.explained_variance_ratio_\n",
    "explained_variance_df = pd.DataFrame(data={'Explained Variance': explained_variances},\n",
    "                                     index=range(1, len(explained_variances) + 1))\n",
    "explained_variance_df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67be79a",
   "metadata": {},
   "source": [
    "cumulative_explained_variance = np.cumsum(explained_variances)\n",
    "cumulative_explained_variance_df = pd.DataFrame(data={'Cumulative Explained Variance': cumulative_explained_variance},\n",
    "                                                index=range(1, len(cumulative_explained_variance) + 1))\n",
    "cumulative_explained_variance_df.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ef327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd0ea887",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba86cd0",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "final_data_pos=[]\n",
    "for channel in (tqdm(range(len(pos_cut)))):\n",
    "    channel_clusters= hdbscan_clustering(pos_cut[channel],n_pos[channel],prova.iloc[:,channel])\n",
    "    final_data_pos.append(channel_clusters)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1668da9d",
   "metadata": {},
   "source": [
    "BL (window 3000, thresh 4) (less function) fuzzy (1.8, 4, 3.99)   \n",
    "BL (window 300) (less function) fuzzy (19, 18, 9)   \n",
    "BL (window 300) (less function) dbscan (30, 9)   \n",
    "BL (window 300) (bit less function std) fuzzy (8.9, 18.2, 17.8)   \n",
    "BL (window 300) (more cut function) fuzzy (8.9, 17.7, 18.3)   \n",
    "BL (window 300) (more cut function) dbscan (29, 6)   \n",
    "BL (less cut function) fuzzy: (15, 8 ,15)   \n",
    "\n",
    "KA (window 300, thresh 4) (less function) fuzzy (3.8, 4, 1.9)   \n",
    "KA (window 3000, thresh 4) (less function) fuzzy (2.6, 1.2, 2.8)   \n",
    "KA stimualtion 3 clusters fuzzy: (13, 6, 12)   \n",
    "KA stim (window 300) (new cut function) (1.17,2.55,2.37)   \n",
    "\n",
    "firing rate between 0.16 and 2 Hz\n",
    "fr=len(cluster)*10000/len(alldata)=0.16-:2\n",
    "len(cluster)=len(spike_list)/n_clusters\n",
    "len(spike_list)*10.000/n_clusters*len(alldata)=0.16-2\n",
    "n_min=10.000*len(spike_list)/2*len(alldata)\n",
    "n_max=10.000*len(spike_list)/0.16*len(alldata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb7976b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "\n",
    "final_data_neg=[]\n",
    "for channel in (tqdm(range(len(neg_cut)))):\n",
    "    channel_clusters= hdbscan_clustering(neg_cut[channel],n_neg[channel],data)\n",
    "    final_data_neg.append(channel_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da37f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# togliere dal best score il DB score e usare solo il silhouette score ma su 15 prove\n",
    "# fare scrematura una volta formati i clusters, togliendo gli spike con distanza DTW sopra soglia\n",
    "# provare anche DTW tra medie di cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5882bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_data_pos=[]\n",
    "for channel in (tqdm(range(len(pos_cut)))):\n",
    "    channel_clusters=nested_clus(pos_cut[channel],'fuzzy',n_pos[channel],prova.iloc[:,channel])\n",
    "    final_data_pos.append(channel_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ab0c17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_data_neg=[]\n",
    "print(name_data)\n",
    "for channel in (tqdm(range(len(neg_cut)))):\n",
    "    channel_clusters=nested_clus(neg_cut[channel],'fuzzy',n_neg[channel],prova.iloc[:,channel])\n",
    "    final_data_neg.append(channel_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2b9409",
   "metadata": {},
   "source": [
    "BL (less cut function) (window 3000, thresh4) fuzzy: (3.5, 3.5, 1.6) silhouette: 0.231    \n",
    "BL (less cut function) (window 300) fuzzy: (17, 15, 6) silhouette: 0.215    \n",
    "BL (more cut function) (window 300) fuzzy: (15, 16, 7) silhouette: 0.218    \n",
    "BL (less cut function) fuzzy: (13, 13, 6) silhouette: 0.226    \n",
    "\n",
    "KA (less cut function) (window 300, thresh4) fuzzy: (1.9, 1.12, 1.9) silhouette: 0.229   \n",
    "KA (less cut function) (window 3000, thresh4) fuzzy: (1.4, 0.89, 1.4) silhouette: 0.223    \n",
    "KA stimulation 3 clusters fuzzy: (3.9, 3.7, 2) silhouette: 0.214    \n",
    "KA stimulation (more cut function) (window 3000) fuzzy: (2, 3.9, 3.7) silhouette: 0.214    \n",
    "KA stimulation (more cut function) (window 300) fuzzy (4.5, 4.4, 2.2) silhouette: 0.204    \n",
    "KA stimulation (more cut function) (window 300) dbscan (10.8,10.8)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d998427b",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886561c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_data_pos[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a86cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366384fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neurons=[]\n",
    "#min_len=len(final_data_pos[0][0])\n",
    "for electrode in final_data_pos:\n",
    "    for neuron in electrode:\n",
    "        #if len(neuron)>1000:\n",
    "        #min_len=min(min_len,len(neuron))\n",
    "        neurons.append(neuron)\n",
    "        #print(len(neuron))\n",
    "print('positive neurons:',len(neurons))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd16f094",
   "metadata": {},
   "outputs": [],
   "source": [
    "for electrode in final_data_neg:\n",
    "    for neuron in electrode:\n",
    "        #if len(neuron)>1000:\n",
    "        neurons.append(neuron)\n",
    "        min_len=min(min_len,len(neuron))\n",
    "        print(len(neuron))\n",
    "print('negative neurons: ',len(neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddb7f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neurons[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4c2f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_neur=[]\n",
    "for neuron in neurons:\n",
    "    neu=neuron#[0:min_len]\n",
    "    adj_neur.append(neu)\n",
    "print(min_len,len(adj_neur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2de168b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24b9e1bc",
   "metadata": {},
   "source": [
    "neurons = []\n",
    "lens=[]\n",
    "for electrode in final_data_pos:\n",
    "    for neuron in electrode:\n",
    "        if len(neuron)>1000:\n",
    "            lens.append(len(neuron))\n",
    "for neuron in final_data_neg:\n",
    "    for neuron in electrode:\n",
    "        if len(neuron)>1000:\n",
    "            lens.append(len(neuron))\n",
    "\n",
    "avg_len=int(np.mean(lens))\n",
    "for electrode in final_data_pos:\n",
    "    for neuron in electrode:\n",
    "        if len(neuron)>1000:\n",
    "            print(len(neuron))\n",
    "            diff = avg_len-len(neuron)\n",
    "            if diff<0:\n",
    "                neurons.append(neuron[0:avg_len])\n",
    "            else:\n",
    "                neurons.append(np.concatenate((neuron,np.zeros([diff]))))\n",
    "print(len(neurons),avg_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b88805",
   "metadata": {},
   "source": [
    "for neuron in final_data_neg:\n",
    "    for neuron in electrode:\n",
    "        if len(neuron)>1000:\n",
    "            print(len(neuron))\n",
    "            diff = avg_len-len(neuron)\n",
    "            if diff<0:\n",
    "                neurons.append(neuron[0:avg_len])\n",
    "            else:\n",
    "                neurons.append(np.concatenate((neuron,np.zeros([diff]))))\n",
    "print(len(neurons),avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2954bc90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71c4d48b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "adj_neur=[]\n",
    "counter = 0\n",
    "max_len=0\n",
    "\n",
    "for neu in neurons:\n",
    "    print('counter: ',counter,neu.shape[0])\n",
    "    if neu.shape[0]>max_len:\n",
    "        max_len=neu.shape[0]\n",
    "    counter+=1\n",
    "for neuron in neurons:\n",
    "    if neuron.shape[0]<=max_len:\n",
    "        diff = max_len-neuron.shape[0]\n",
    "        adj_neur.append(np.concatenate((neuron,np.zeros([diff]))))\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37fb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data = 'After'+name_data+'.txt'\n",
    "print(name_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac48f07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/Users/Gaia_1/Desktop/tesi/Data after SS/%s.txt\" % save_data,adj_neur, delimiter=', ', fmt='%12.8f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac710f3",
   "metadata": {},
   "source": [
    "## Point Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97aa178",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons=[]\n",
    "for neuron in final_data_pos:\n",
    "    neurons.append(neuron)\n",
    "for neuron in final_data_neg:\n",
    "    neurons.append(neuron)\n",
    "neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e80e211",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc889e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=randint(0,len(neurons))\n",
    "#x=21\n",
    "print('neur: ',x)\n",
    "#if len(neurons[x])>1000:\n",
    "print('length: ',len(neurons[x]))\n",
    "data_healthy=neurons[x]\n",
    "ISI_healthy = np.diff(data_healthy)/10000\n",
    "#else:\n",
    "    #print('try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6508b49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "locs_diff=np.diff(data_healthy)\n",
    "#plt.axis([-3,500,0,0.05])\n",
    "plt.hist(ISI_healthy, bins=50, density=False, alpha=0.5, color='blue', edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13893ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_estimate,ppc_trace = Bayesian_mixture_model(ISI_healthy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9528a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(ISI_healthy, bins=50, density=False, alpha=0.5, color='blue', edgecolor='black')\n",
    "#plt.plot(hist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b973e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(hist[0]/max(hist[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e18bec1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist[1][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a4541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(ISI_healthy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7af302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ISI_healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db62586",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(ISI_healthy/max(ISI_healthy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0627eed8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(ISI_healthy/max(ISI_healthy),bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e1f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed26b85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bins = np.arange(0, .5, 1e-3) \n",
    "plt.figure (figsize=(10,4))\n",
    "\n",
    "hist = np.histogram(ppc_trace['posterior_predictive']['like'].values,bins=bins)\n",
    "#plt.axis([0,0.3,0,160])\n",
    "a= plt.hist(ISI_healthy,bins)\n",
    "plt.plot(hist[1][:-1],hist[0]/1000,linewidth=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a815b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_samples=[]\n",
    "for i in list(ppc_trace['posterior_predictive']['like'].values):\n",
    "    lista_samples.extend(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393dbbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, _ = np.histogram(ISI_healthy, bins) \n",
    "prob_emp = counts / np.sum(counts)\n",
    "counts, _ = np.histogram(lista_samples, bins) \n",
    "prob_model = counts / np.sum(counts)\n",
    "\n",
    "Femp = np.cumsum(prob_emp)           \n",
    "Fmodel = np.cumsum(prob_model)          \n",
    "plt.figure()\n",
    "plt.plot(bins[:-1], Femp)                \n",
    "plt.plot(bins[:-1], Fmodel, 'r')       \n",
    "#plt.xlim([0, 0.2])                  \n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('CDF')\n",
    "plt.legend(['Empirical','Model'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8743c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "Nlow = len(ISI_healthy)  \n",
    "# Plot the confidence bounds\n",
    "plt.plot([0, 1], [x + 1.36 / np.sqrt(Nlow) for x in [0, 1]], 'r:')\n",
    "plt.plot([0, 1], [x - 1.36 / np.sqrt(Nlow) for x in [0, 1]], 'r:')\n",
    "plt.plot(Femp, Fmodel)\n",
    "plt.axis([0, 1, 0, 1])         \n",
    "plt.xlabel('Model CDF')\n",
    "plt.ylabel('Empirical CDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e8380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc962eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6c40a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6a2d399",
   "metadata": {},
   "source": [
    "# Multiple channel point process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012ee18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame()\n",
    "list_neurons = neurons\n",
    "counter=0\n",
    "print('Original number of neurons: ',len(list_neurons))\n",
    "net=name_data\n",
    "for neuron in list_neurons:\n",
    "    neuron=neuron[neuron>0*10000]\n",
    "    neuron=neuron[neuron<200*10000]\n",
    "    print('  Neuron with ',neuron.shape[0],'spikes')\n",
    "    if neuron.shape[0]>1000:\n",
    "\n",
    "        counter+=1\n",
    "    else:\n",
    "        print('    Excluded neuron with n spikes = ',neuron.shape[0])\n",
    "        continue\n",
    "\n",
    "    ISI_healthy = np.diff(neuron)/10000\n",
    "\n",
    "\n",
    "    map_estimate = Bayesian_mixture_model(ISI_healthy)\n",
    "    if 'Healthy' in net:\n",
    "        print('target Healthy')\n",
    "        map_estimate['Target']=0\n",
    "\n",
    "    elif 'healthy' in net:\n",
    "        print('target healthy')\n",
    "        map_estimate['Target']=0\n",
    "\n",
    "    elif 'health' in net:\n",
    "        print('target health')\n",
    "        map_estimate['Target']=0\n",
    "\n",
    "    else:\n",
    "        print('target pathological')\n",
    "        map_estimate['Target']=1\n",
    "\n",
    "    if 'KA' in net:\n",
    "        map_estimate['Stimulation']=1\n",
    "\n",
    "    elif 'stimulation' in net:\n",
    "        map_estimate['Stimulation']=1\n",
    "    else:\n",
    "        map_estimate['Stimulation']=0\n",
    "\n",
    "    df = pd.DataFrame.from_dict(map_estimate,orient='index')\n",
    "    dataframe = pd.concat([dataframe,df],axis = 1)\n",
    "print('Final number of neurons: ',counter)\n",
    "print('Target = ',target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088dafb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = dataframe.T\n",
    "final.to_csv('Data after PP/DataAfter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f05783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d895b87",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f67edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_visualizer(trials_obj,n_models,choice=False,**choice_var):\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    performance = [1-t['result']['loss'] for t in trials_obj.trials]\n",
    "    \n",
    "    \n",
    "    hyperparam= list(trials_obj.trials[0]['misc']['vals'].keys())\n",
    "    \n",
    "    values_dict ={}\n",
    "    \n",
    "    for i in hyperparam:\n",
    "        \n",
    "        values_dict[i]=[]\n",
    "        \n",
    "        for j in trials_obj.trials:\n",
    "            \n",
    "            if(len(j['misc']['vals'][i])==0):\n",
    "                \n",
    "                values_dict[i].append(np.NaN)\n",
    "                \n",
    "            else:\n",
    "            \n",
    "                values_dict[i].append(j['misc']['vals'][i][0])\n",
    "                \n",
    "    out = pd.DataFrame.from_dict(values_dict)\n",
    "    \n",
    "    out['performance'] = performance\n",
    "    \n",
    "    out=out.sort_values(by=['performance'])\n",
    "    \n",
    "    \n",
    "    if choice:\n",
    "        \n",
    "        for i in list(choice_var.keys()):\n",
    "        \n",
    "            for j,_ in enumerate(choice_var[i]):\n",
    "        \n",
    "                out[i]=out[i].replace(j,choice_var[i][j])\n",
    "    \n",
    "    return out.tail(n_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Data after PP/Data')\n",
    "dataset = dataset.drop(['Unnamed: 0'],axis=1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bee329",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
