{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8babe8d2",
   "metadata": {},
   "source": [
    "# Spike sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe226e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#da fare:\n",
    "# soglia silhouette >0.4 (non >=)\n",
    "# SPIKE SORTING E POINT PROCESS MODELING SEPARATI PER BL E STIM PER POI TRAINARE IL MODELLO SULLE DUE COSE SEPARATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5933ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_neurons=[]\n",
    "final_firing=[]\n",
    "from NewLibraryENGcopia import *\n",
    "import glob\n",
    "#final=[]\n",
    "list_dir=glob.glob(\"/Users/Gaia_1/Desktop/allh5filestutto/*.h5\")\n",
    "output_path='/Users/Gaia_1/Desktop/tesi/Data after SS new'\n",
    "for file in tqdm(list_dir):\n",
    "    target=1\n",
    "    stim=0\n",
    "    if 'health' in file:\n",
    "        target=0\n",
    "    if 'stimulation' in file:\n",
    "        stim=1\n",
    "    file_name = file.split(\"/\")[-1]\n",
    "    print(file_name,':','target',target,'stimulation',stim)\n",
    "    neurons,firing=spike_sorting(file,output_path)\n",
    "    #df=poiproc(neurons,target,stim)\n",
    "    #final.append(df)\n",
    "    final_neurons.append(neurons)\n",
    "    final_firing.append(firing)\n",
    "    print(firing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bf23fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in final_firings:\n",
    "    if 'stimulation' in f[0]:\n",
    "        numerical_values = [float(arr[0]) for arr in f[1:]]\n",
    "        mean_value = sum(numerical_values) / len(numerical_values)\n",
    "        print(\"Mean STIM:\", mean_value)\n",
    "    else:\n",
    "        numerical_values = [float(arr[0]) for arr in f[1:]]\n",
    "        mean_value = sum(numerical_values) / len(numerical_values)\n",
    "        print(\"Mean BL:\", mean_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd45f217",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "list_dir=glob.glob(\"/Users/Gaia_1/Desktop/allh5filestutto/*.h5\")\n",
    "for file in list_dir:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16df5b6",
   "metadata": {},
   "source": [
    "# Point Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99f8455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NewLibraryENGcopia import *\n",
    "import glob\n",
    "final=[]\n",
    "output_path='/Users/Gaia_1/Desktop/tesi/Data after SS'\n",
    "list_dir=glob.glob(output_path+\"/*\")\n",
    "for file in tqdm(list_dir):\n",
    "    target=1\n",
    "    stim=0\n",
    "    if 'health' in file:\n",
    "        target=0\n",
    "    if 'stimulation' in file:\n",
    "        stim=1\n",
    "    list_neurons = np.genfromtxt(file, delimiter=',')\n",
    "    df,counter=poiproc(list_neurons,target,stim)\n",
    "    final.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a10e9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d42f2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e586f45e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e74baf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5371692",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, .5, 1e-3) \n",
    "plt.figure (figsize=(14,10))\n",
    "hist = np.histogram(ppc_trace['posterior_predictive']['like'].values,bins=bins)\n",
    "#plt.axis([-0.01,0.13,0,160])\n",
    "a= plt.hist(ISI_healthy,bins)\n",
    "plt.plot(hist[1][:-1],hist[0]/1000,linewidth=3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf106785",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_samples=[]\n",
    "for i in list(ppc_trace['posterior_predictive']['like'].values):\n",
    "    lista_samples.extend(i)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85271c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, _ = np.histogram(ISI_healthy, bins) \n",
    "prob_emp = counts / np.sum(counts)\n",
    "counts, _ = np.histogram(lista_samples, bins) \n",
    "prob_model = counts / np.sum(counts)\n",
    "\n",
    "Femp = np.cumsum(prob_emp)           \n",
    "Fmodel = np.cumsum(prob_model)          \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(bins[:-1], Femp)                \n",
    "plt.plot(bins[:-1], Fmodel, 'r')       \n",
    "#plt.xlim([0, 0.2])                  \n",
    "#plt.xlabel('Time [s]')\n",
    "#plt.ylabel('CDF')\n",
    "plt.legend(['Empirical','Model'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79da4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "Nlow = len(ISI_healthy)  \n",
    "# Plot the confidence bounds\n",
    "plt.plot([0, 1], [x + 1.36 / np.sqrt(Nlow) for x in [0, 1]], 'r:')\n",
    "plt.plot([0, 1], [x - 1.36 / np.sqrt(Nlow) for x in [0, 1]], 'r:')\n",
    "plt.plot(Femp, Fmodel)\n",
    "#plt.axis([0, 1, 0, 1])         \n",
    "#plt.xlabel('Model CDF')\n",
    "#plt.ylabel('Empirical CDF')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3b6cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2a4970",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame()\n",
    "list_neurons = neurons\n",
    "counter=0\n",
    "target=0\n",
    "print('Original number of neurons: ',len(list_neurons))\n",
    "for neuron in list_neurons:\n",
    "    neuron=neuron[neuron>0*10000]\n",
    "    neuron=neuron[neuron<200*10000]\n",
    "    print('  Neuron with ',neuron.shape[0],'spikes')\n",
    "    if neuron.shape[0]>100:\n",
    "\n",
    "        counter+=1\n",
    "    else:\n",
    "        print('    Excluded neuron with n spikes = ',neuron.shape[0])\n",
    "        continue\n",
    "\n",
    "    ISI_healthy = np.diff(neuron)/10000\n",
    "\n",
    "\n",
    "    map_estimate,ppc_trace = this_Bayesian_mixture_model(ISI_healthy)\n",
    "    #trace(ppc_trace)\n",
    "    df = pd.DataFrame.from_dict(map_estimate,orient='index')\n",
    "    dataframe = pd.concat([dataframe,df],axis = 1)\n",
    "print('Final number of neurons: ',counter)\n",
    "print('Target = ',target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80154ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def this_Bayesian_mixture_model(ISI_data):\n",
    "    with pm.Model() as model:\n",
    "        ##### WALD DISTRIBUTION (INVERSE GAUSSIAN)\n",
    "        mu1 = pm.Uniform('mu1',lower=0.01,upper=0.1)\n",
    "        lam1 = pm.Uniform('lam1',lower=0.001,upper=0.04)\n",
    "        obs1 = pm.Wald.dist(mu=mu1,lam=lam1)\n",
    "\n",
    "\n",
    "        mu2 = pm.Uniform('mu2',lower=0,upper=0.2)\n",
    "        sigma2 = pm.Uniform('sigma2',lower=0.0001,upper=0.5)\n",
    "        obs2 = pm.TruncatedNormal.dist(mu=mu2, sigma=sigma2, lower=0.0)\n",
    "\n",
    "        mu3 = pm.Uniform('mu3',lower=0.1,upper=0.6)\n",
    "        sigma3 = pm.Uniform('sigma3',lower=0.0001,upper=0.5)\n",
    "        obs3 = pm.TruncatedNormal.dist(mu=mu3, sigma=sigma3, lower=0.0)\n",
    "\n",
    "\n",
    "        w = pm.Dirichlet('w', a=np.array([1., .4, .4]))\n",
    "        #w = pm.Dirichlet('w', a=np.array([1., .4]))\n",
    "\n",
    "        like = pm.Mixture('like', w=w, comp_dists = [obs1, obs2, obs3], observed=ISI_data)\n",
    "        #like = pm.Mixture('like', w=w, comp_dists = [obs1, obs2], observed=ISI_data)\n",
    "\n",
    "        step = pm.NUTS(target_accept=0.9)\n",
    "        trace = pm.sample(step=step,draws=1000,chains=4,tune=1000,cores=4)\n",
    "        \n",
    "        ppc_trace = pm.sample_posterior_predictive(trace,model=model)\n",
    "        if ppc_trace==0:\n",
    "            print('ppc_trace not succesful')\n",
    "        '''\n",
    "        bins = np.arange(0, .5, 1e-3) \n",
    "        plt.figure (figsize=(14,10))\n",
    "        hist = np.histogram(ppc_trace['posterior_predictive']['like'].values,bins=bins)\n",
    "        #plt.axis([-0.01,0.13,0,160])\n",
    "        a= plt.hist(ISI_healthy,bins)\n",
    "        plt.plot(hist[1][:-1],hist[0]/1000,linewidth=3)\n",
    "        plt.show()\n",
    "\n",
    "        lista_samples=[]\n",
    "        for i in list(ppc_trace['posterior_predictive']['like'].values):\n",
    "            lista_samples.extend(i)        \n",
    "        \n",
    "        counts, _ = np.histogram(ISI_healthy, bins) \n",
    "        prob_emp = counts / np.sum(counts)\n",
    "        counts, _ = np.histogram(lista_samples, bins) \n",
    "        prob_model = counts / np.sum(counts)\n",
    "\n",
    "        Femp = np.cumsum(prob_emp)           \n",
    "        Fmodel = np.cumsum(prob_model)          \n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(bins[:-1], Femp)                \n",
    "        plt.plot(bins[:-1], Fmodel, 'r')       \n",
    "        #plt.xlim([0, 0.2])                  \n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('CDF')\n",
    "        plt.legend(['Empirical','Model'])\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        Nlow = len(ISI_healthy)  \n",
    "        # Plot the confidence bounds\n",
    "        plt.plot([0, 1], [x + 1.36 / np.sqrt(Nlow) for x in [0, 1]], 'r:')\n",
    "        plt.plot([0, 1], [x - 1.36 / np.sqrt(Nlow) for x in [0, 1]], 'r:')\n",
    "        plt.plot(Femp, Fmodel)\n",
    "        #plt.axis([0, 1, 0, 1])         \n",
    "        plt.xlabel('Model CDF')\n",
    "        plt.ylabel('Empirical CDF')\n",
    "        plt.show()\n",
    "        '''\n",
    "        \n",
    "    map_estimate = pm.find_MAP(model=model)\n",
    "    \n",
    "    del map_estimate['w_simplex__']\n",
    "    del map_estimate['mu1_interval__']\n",
    "    del map_estimate['lam1_interval__']\n",
    "    del map_estimate['mu2_interval__']\n",
    "    del map_estimate['sigma2_interval__']\n",
    "    del map_estimate['mu3_interval__']\n",
    "    del map_estimate['sigma3_interval__']\n",
    "    \n",
    "    map_estimate['w1'] = map_estimate['w'][0]\n",
    "    map_estimate['w2'] = map_estimate['w'][1]\n",
    "    map_estimate['w3'] = map_estimate['w'][2]\n",
    "\n",
    "    del map_estimate['w']\n",
    "\n",
    "\n",
    "    return map_estimate, ppc_trace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
