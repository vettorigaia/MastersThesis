{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "891d30d1",
   "metadata": {},
   "source": [
    "# Point Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42510fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from NewLibraryENGcopia import *\n",
    "import glob\n",
    "final=[]\n",
    "output_path='/Users/Gaia_1/Desktop/Data after SS thresh 3'\n",
    "list_dir=glob.glob(output_path+\"/*.txt\")\n",
    "#for file in tqdm(list_dir):\n",
    "#file='/Users/Gaia_1/Downloads/After2018-11-28T12-35-18Pop2 stimulation.h5.txt'\n",
    "for file in list_dir:\n",
    "    target=1\n",
    "    stim=0\n",
    "    if 'health' in file:\n",
    "        target=0\n",
    "    if 'stimulation' in file:\n",
    "        stim=1\n",
    "    print(file,'target',target,'stimulation',stim)\n",
    "    list_neurons = np.genfromtxt(file, delimiter=',')\n",
    "    df=this_poiproc(list_neurons,target,stim)\n",
    "    final.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76549620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=this_single_poiproc(new_list_neurons,0,1,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a0e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_length = len(list_neurons) // 3\n",
    "\n",
    "# Create a new NumPy array to store pairs of arrays\n",
    "new_list_neurons = np.empty(new_length, dtype=object)\n",
    "\n",
    "# Iterate through the original array, combining every pair of arrays\n",
    "for i in range(0, new_length * 3, 3):\n",
    "    new_list_neurons[i // 3] = np.array([list_neurons[i], list_neurons[i + 1],list_neurons[i + 2]])\n",
    "\n",
    "# Print the new array\n",
    "print(len(new_list_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6b3501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59be711b",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad82109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def this_Bayesian_mixture_model(ISI_data):\n",
    "    import scipy.stats as st\n",
    "    with pm.Model() as model:\n",
    "        ##### WALD DISTRIBUTION (INVERSE GAUSSIAN)\n",
    "        mu1 = pm.Uniform('mu1',lower=0.03,upper=0.1)\n",
    "        lam1 = pm.Uniform('lam1',lower=0.000001,upper=0.04)\n",
    "        obs1 = pm.Wald.dist(mu=mu1,lam=lam1)\n",
    "\n",
    "\n",
    "        mu2 = pm.Uniform('mu2',lower=0.09,upper=0.4)\n",
    "        sigma2 = pm.Uniform('sigma2',lower=0.01,upper=0.7)\n",
    "        obs2 = pm.TruncatedNormal.dist(mu=mu2, sigma=sigma2, lower=0.0)\n",
    "        \n",
    "        w = pm.Dirichlet('w', a=np.array([1., 1.]))\n",
    "        like = pm.Mixture('like', w=w, comp_dists = [obs1, obs2], observed=ISI_data)\n",
    "\n",
    "    map_estimate = pm.find_MAP(model=model)\n",
    "    d= np.linspace(0.00, 1, len(ISI_data))\n",
    "    map_estimate['w1'] = map_estimate['w'][0]\n",
    "    map_estimate['w2'] = map_estimate['w'][1]\n",
    "    \n",
    "    mu1=map_estimate['mu1']\n",
    "    mu2=map_estimate['mu2']\n",
    "    \n",
    "    #lam1=map_estimate['lam1']\n",
    "    lam1=0.008\n",
    "    sigma2=map_estimate['sigma2']\n",
    "    \n",
    "    w1=map_estimate['w1']\n",
    "    w2=map_estimate['w2']\n",
    "    \n",
    "    pdf = w1*st.invgauss.pdf(d, mu1/lam1, scale = lam1) + w2*st.norm.pdf(d, mu2, sigma2)\n",
    "    bins = np.arange(0, 0.5, 1e-3)\n",
    "    \n",
    "    plt.hist(ISI_data, bins, color='orange', alpha=0.7, label='Histogram',density=True)\n",
    "    plt.plot(d, pdf, color='blue', label='PDF')\n",
    "    #plt.xlim(0, 0.3)\n",
    "    plt.show()\n",
    "\n",
    "    cdf_2gauss = lambda x: w1 * st.invgauss.cdf(x,mu1/lam1, scale = lam1) + w2 * st.norm.cdf(x, mu2, sigma2)\n",
    "    ks_score=st.ks_1samp(ISI_data[ISI_data>0],  cdf_2gauss, method = 'asymp')\n",
    "    print('ks score: ',ks_score)\n",
    "    \n",
    "    del map_estimate['w_simplex__']\n",
    "    del map_estimate['mu1_interval__']\n",
    "    del map_estimate['lam1_interval__']\n",
    "    del map_estimate['mu2_interval__']\n",
    "    del map_estimate['sigma2_interval__']\n",
    "\n",
    "    \n",
    "    del map_estimate['w']\n",
    "\n",
    "    print(map_estimate)\n",
    "    return map_estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e6f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def this_poiproc(neurons,target,stim):\n",
    "    from scipy.stats import ks_2samp\n",
    "    dataframe = pd.DataFrame()\n",
    "    #counter_net=1\n",
    "    counter=0\n",
    "    #for net in list_dir_ok:\n",
    "    #print(counter_net,') ',net)\n",
    "    #counter_net+=1\n",
    "    list_neurons = neurons #np.genfromtxt(net, delimiter=',')\n",
    "    counter=0\n",
    "    print('Original number of neurons: ',len(list_neurons))\n",
    "    for neuron in tqdm(list_neurons):\n",
    "        neuron=neuron[neuron>0*10000]\n",
    "        neuron=neuron[neuron<200*10000]\n",
    "        print('  Neuron with ',neuron.shape[0],'spikes')\n",
    "        if neuron.shape[0]>10:\n",
    "            \n",
    "            counter+=1\n",
    "        else:\n",
    "            print('    Excluded neuron with n spikes = ',neuron.shape[0])\n",
    "            continue\n",
    "        \n",
    "        ISI_healthy = np.diff(neuron)/10000\n",
    "        map_estimate = this_Bayesian_mixture_model(ISI_healthy)\n",
    "        map_estimate['Target']=target\n",
    "        map_estimate['Stimulation']=stim\n",
    "        df = pd.DataFrame.from_dict(map_estimate,orient='index')\n",
    "        dataframe = pd.concat([dataframe,df],axis = 1)\n",
    "    print('Final number of neurons: ',counter)\n",
    "    print('Target = ',target)\n",
    "    #ks_2samp(lista_samples,ISI_healthy,mode = 'asymp')\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2590569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def this_single_poiproc(neurons,target,stim,which):\n",
    "    from scipy.stats import ks_2samp\n",
    "    dataframe = pd.DataFrame()\n",
    "    #counter_net=1\n",
    "    #list_neurons = neurons #np.genfromtxt(net, delimiter=',')\n",
    "    print('Original number of neurons: ',len(neurons))\n",
    "    neuron=list_neurons[which]\n",
    "    neuron=neuron[neuron>0*10000]\n",
    "    neuron=neuron[neuron<200*10000]\n",
    "    print('  Neuron with ',neuron.shape[0],'spikes')\n",
    "    if neuron.shape[0]<10:\n",
    "        print('    Excluded neuron with n spikes = ',neuron.shape[0])\n",
    "\n",
    "    ISI_healthy = np.diff(neuron)/10000\n",
    "    map_estimate = this_Bayesian_mixture_model(ISI_healthy)\n",
    "    map_estimate['Target']=target\n",
    "    map_estimate['Stimulation']=stim\n",
    "    df = pd.DataFrame.from_dict(map_estimate,orient='index')\n",
    "    dataframe = pd.concat([dataframe,df],axis = 1)\n",
    "    print('Target = ',target)\n",
    "    #ks_2samp(lista_samples,ISI_healthy,mode = 'asymp')\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd74dae5",
   "metadata": {},
   "source": [
    "def this_Bayesian_mixture_model(ISI_data):\n",
    "    import scipy.stats as st\n",
    "    with pm.Model() as model:\n",
    "        ##### WALD DISTRIBUTION (INVERSE GAUSSIAN)\n",
    "        mu1 = pm.Uniform('mu1',lower=0.03,upper=0.1)\n",
    "        lam1 = pm.Uniform('lam1',lower=0.000001,upper=0.04)\n",
    "        obs1 = pm.Wald.dist(mu=mu1,lam=lam1)\n",
    "\n",
    "\n",
    "        mu2 = pm.Uniform('mu2',lower=0.02,upper=0.04)\n",
    "        sigma2 = pm.Uniform('sigma2',lower=0.01,upper=0.7)\n",
    "        obs2 = pm.TruncatedNormal.dist(mu=mu2, sigma=sigma2, lower=0.0)\n",
    "\n",
    "        mu3 = pm.Uniform('mu3',lower=0.04,upper=0.6)\n",
    "        sigma3 = pm.Uniform('sigma3',lower=0.01,upper=0.7)\n",
    "        obs3 = pm.TruncatedNormal.dist(mu=mu3, sigma=sigma3, lower=0.0)\n",
    "        \n",
    "        w = pm.Dirichlet('w', a=np.array([1., 0.3, 0.3]))\n",
    "        like = pm.Mixture('like', w=w, comp_dists = [obs1, obs2, obs3], observed=ISI_data)\n",
    "\n",
    "        '''\n",
    "        if counter==9:\n",
    "            step = pm.NUTS(target_accept=0.9)\n",
    "            trace = pm.sample(step=step,draws=1000,chains=1,tune=1000,cores=4)\n",
    "            ppc_trace = pm.sample_posterior_predictive(trace,model=model)\n",
    "            bins = np.arange(0, .5, 1e-3) \n",
    "            plt.figure (figsize=(14,10))\n",
    "            hist = np.histogram(ppc_trace['posterior_predictive']['like'].values,bins=bins)\n",
    "            #plt.axis([-0.01,0.13,0,160])\n",
    "            a= plt.hist(ISI_data,bins)\n",
    "            plt.plot(hist[1][:-1],hist[0]/1000,linewidth=3)\n",
    "            plt.show()\n",
    "        '''\n",
    "        \n",
    "    map_estimate = pm.find_MAP(model=model)\n",
    "    d= np.linspace(0.00, 1, len(ISI_data))\n",
    "    map_estimate['w1'] = map_estimate['w'][0]\n",
    "    map_estimate['w2'] = map_estimate['w'][1]\n",
    "    map_estimate['w3'] = map_estimate['w'][2]\n",
    "    \n",
    "    mu1=map_estimate['mu1']\n",
    "    mu2=map_estimate['mu2']\n",
    "    mu3=map_estimate['mu3']\n",
    "    \n",
    "    lam1=map_estimate['lam1']\n",
    "    sigma2=map_estimate['sigma2']\n",
    "    sigma3=map_estimate['sigma3']\n",
    "    \n",
    "    w1=map_estimate['w1']\n",
    "    w2=map_estimate['w2']\n",
    "    w3=map_estimate['w3']\n",
    "    \n",
    "    pdf = w1*st.invgauss.pdf(d, mu1/lam1, scale = lam1) + w2*st.norm.pdf(d, mu2, sigma2) + w3*st.norm.pdf(d, mu3, sigma3)\n",
    "    bins = np.arange(0, 0.5, 1e-3)\n",
    "    \n",
    "    plt.hist(ISI_data, bins, color='orange', alpha=0.7, label='Histogram',density=True)\n",
    "    plt.plot(d, pdf, color='blue', label='PDF')\n",
    "    plt.xlim(0, 0.5)\n",
    "    plt.show()\n",
    "\n",
    "    cdf_2gauss = lambda x: w1 * st.invgauss.cdf(x,mu1/lam1, scale = lam1) + w2 * st.norm.cdf(x, mu2, sigma2) + w3*st.norm.cdf(x, mu3, sigma3)\n",
    "    ks_score=st.ks_1samp(ISI_data[ISI_data>0],  cdf_2gauss, method = 'asymp')\n",
    "    print('ks score: ',ks_score)\n",
    "    \n",
    "    del map_estimate['w_simplex__']\n",
    "    del map_estimate['mu1_interval__']\n",
    "    del map_estimate['lam1_interval__']\n",
    "    del map_estimate['mu2_interval__']\n",
    "    del map_estimate['sigma2_interval__']\n",
    "    del map_estimate['mu3_interval__']\n",
    "    del map_estimate['sigma3_interval__']\n",
    "\n",
    "    \n",
    "    del map_estimate['w']\n",
    "\n",
    "    print(map_estimate)\n",
    "    return map_estimate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e10053b",
   "metadata": {},
   "source": [
    "def this_Bayesian_mixture_model(ISI_data):\n",
    "    import scipy.stats as st\n",
    "    with pm.Model() as model:\n",
    "        ##### WALD DISTRIBUTION (INVERSE GAUSSIAN)\n",
    "        mu1 = pm.Uniform('mu1',lower=0.03,upper=0.04)\n",
    "        lam1 = pm.Uniform('lam1',lower=0.01,upper=0.4)\n",
    "        obs1 = pm.Wald.dist(mu=mu1,lam=lam1)\n",
    "\n",
    "\n",
    "        mu2 = pm.Uniform('mu2',lower=0.02,upper=0.04)\n",
    "        sigma2 = pm.Uniform('sigma2',lower=0.01,upper=0.7)\n",
    "        obs2 = pm.TruncatedNormal.dist(mu=mu2, sigma=sigma2, lower=0.0)\n",
    "\n",
    "        mu3 = pm.Uniform('mu3',lower=0.04,upper=0.6)\n",
    "        sigma3 = pm.Uniform('sigma3',lower=0.01,upper=0.7)\n",
    "        obs3 = pm.TruncatedNormal.dist(mu=mu3, sigma=sigma3, lower=0.0)\n",
    "        \n",
    "        mu4 = pm.Uniform('mu4',lower=0.04,upper=0.05)\n",
    "        lam4 = pm.Uniform('lam4',lower=0.0001,upper=0.04)\n",
    "        obs4 = pm.Wald.dist(mu=mu4,lam=lam4)        \n",
    "        \n",
    "        w = pm.Dirichlet('w', a=np.array([0.5, 1., 1e-10, 0.5]))\n",
    "        like = pm.Mixture('like', w=w, comp_dists = [obs1, obs2, obs3, obs4], observed=ISI_data)\n",
    "\n",
    "        '''\n",
    "        if counter==9:\n",
    "            step = pm.NUTS(target_accept=0.9)\n",
    "            trace = pm.sample(step=step,draws=1000,chains=1,tune=1000,cores=4)\n",
    "            ppc_trace = pm.sample_posterior_predictive(trace,model=model)\n",
    "            bins = np.arange(0, .5, 1e-3) \n",
    "            plt.figure (figsize=(14,10))\n",
    "            hist = np.histogram(ppc_trace['posterior_predictive']['like'].values,bins=bins)\n",
    "            #plt.axis([-0.01,0.13,0,160])\n",
    "            a= plt.hist(ISI_data,bins)\n",
    "            plt.plot(hist[1][:-1],hist[0]/1000,linewidth=3)\n",
    "            plt.show()\n",
    "        '''\n",
    "        \n",
    "    map_estimate = pm.find_MAP(model=model)\n",
    "    d= np.linspace(0.00, 1, len(ISI_data))\n",
    "    map_estimate['w1'] = map_estimate['w'][0]\n",
    "    map_estimate['w2'] = map_estimate['w'][1]\n",
    "    map_estimate['w3'] = map_estimate['w'][2]\n",
    "    map_estimate['w4'] = map_estimate['w'][3]\n",
    "    \n",
    "    mu1=map_estimate['mu1']\n",
    "    mu2=map_estimate['mu2']\n",
    "    mu3=map_estimate['mu3']\n",
    "    mu4=map_estimate['mu4']\n",
    "    \n",
    "    lam1=map_estimate['lam1']\n",
    "    sigma2=map_estimate['sigma2']\n",
    "    sigma3=map_estimate['sigma3']\n",
    "    lam4=map_estimate['lam4']\n",
    "    \n",
    "    w1=map_estimate['w1']\n",
    "    w2=map_estimate['w2']\n",
    "    w3=map_estimate['w3']\n",
    "    w4=map_estimate['w4']\n",
    "    \n",
    "    pdf = w1*st.invgauss.pdf(d, mu1/lam1, scale = lam1) + w2*st.norm.pdf(d, mu2, sigma2) + w3*st.norm.pdf(d, mu3, sigma3)+w4*st.invgauss.pdf(d, mu4/lam4, scale = lam4)\n",
    "    bins = np.arange(0, 0.5, 1e-3)\n",
    "    \n",
    "    plt.hist(ISI_data, bins, color='orange', alpha=0.7, label='Histogram',density=True)\n",
    "    plt.plot(d, pdf, color='blue', label='PDF')\n",
    "    #plt.xlim(0, 0.5)\n",
    "    plt.show()\n",
    "\n",
    "    cdf_2gauss = lambda x: w1 * st.invgauss.cdf(x,mu1/lam1, scale = lam1) + w2 * st.norm.cdf(x, mu2, sigma2) + w3*st.norm.cdf(x, mu3, sigma3)+w4 * st.invgauss.cdf(x,mu4/lam4, scale = lam4)\n",
    "    ks_score=st.ks_1samp(ISI_data[ISI_data>0],  cdf_2gauss, method = 'asymp')\n",
    "    print('ks score: ',ks_score)\n",
    "    \n",
    "    del map_estimate['w_simplex__']\n",
    "    del map_estimate['mu1_interval__']\n",
    "    del map_estimate['lam1_interval__']\n",
    "    del map_estimate['mu2_interval__']\n",
    "    del map_estimate['sigma2_interval__']\n",
    "    del map_estimate['mu3_interval__']\n",
    "    del map_estimate['sigma3_interval__']\n",
    "    del map_estimate['mu4_interval__']\n",
    "    del map_estimate['lam4_interval__']\n",
    "\n",
    "    \n",
    "    del map_estimate['w']\n",
    "\n",
    "    print(map_estimate)\n",
    "    return map_estimate\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
