{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c744e6",
   "metadata": {},
   "source": [
    "# Spike Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d87c28b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m file_name \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(file_name,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m,target,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstimulation\u001b[39m\u001b[38;5;124m'\u001b[39m,stim)\n\u001b[0;32m---> 17\u001b[0m neurons,firing\u001b[38;5;241m=\u001b[39mthis_spike_sorting(file,output_path)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#df=poiproc(neurons,target,stim)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#final.append(df)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m final_neurons\u001b[38;5;241m.\u001b[39mappend(neurons)\n",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m, in \u001b[0;36mthis_spike_sorting\u001b[0;34m(input_path, output_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile Reading...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(input_path,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m data_readings \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecording_0\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnalogStream\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStream_0\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChannelData\u001b[39m\u001b[38;5;124m'\u001b[39m][()]\n\u001b[1;32m      7\u001b[0m info \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecording_0\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnalogStream\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStream_0\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInfoChannel\u001b[39m\u001b[38;5;124m'\u001b[39m][()]\n\u001b[1;32m      8\u001b[0m info_table \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(info, columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(info\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mfields\u001b[38;5;241m.\u001b[39mkeys()))\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/h5py/_hl/dataset.py:758\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 758\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_reader\u001b[38;5;241m.\u001b[39mread(args)\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    760\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_neurons=[]\n",
    "final_firing=[]\n",
    "from NewLibraryENGcopia import *\n",
    "import glob\n",
    "#final=[]\n",
    "list_dir=glob.glob(\"/Users/Gaia_1/Desktop/allh5filestutto/*.h5\")\n",
    "output_path='/Users/Gaia_1/Desktop'\n",
    "for file in tqdm(list_dir):\n",
    "    target=1\n",
    "    stim=0\n",
    "    if 'health' in file:\n",
    "        target=0\n",
    "    if 'stimulation' in file:\n",
    "        stim=1\n",
    "    file_name = file.split(\"/\")[-1]\n",
    "    print(file_name,':','target',target,'stimulation',stim)\n",
    "    neurons,firing=this_spike_sorting(file,output_path)\n",
    "    #df=poiproc(neurons,target,stim)\n",
    "    #final.append(df)\n",
    "    final_neurons.append(neurons)\n",
    "    final_firing.append(firing)\n",
    "    print(firing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5525a202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f4c9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7643b471",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198648d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def this_spike_sorting(input_path,output_path):\n",
    "    name_data = input_path.split(\"/\")[-1]\n",
    "    #file reading:\n",
    "    print('File Reading...')\n",
    "    data = h5py.File(input_path,'r')\n",
    "    data_readings = data['Data']['Recording_0']['AnalogStream']['Stream_0']['ChannelData'][()]\n",
    "    info = data['Data']['Recording_0']['AnalogStream']['Stream_0']['InfoChannel'][()]\n",
    "    info_table = pd.DataFrame(info, columns = list(info.dtype.fields.keys()))\n",
    "    labels = info_table['Label']\n",
    "    readings = pd.DataFrame(data = data_readings.transpose(), columns = labels)\n",
    "    fs = 10000 #Sampling Frequency\n",
    "    print('data shape: ',readings.shape)\n",
    "    prova=readings.drop([b'Ref'],axis=1)\n",
    "    #prova=prova.iloc[0:750500, :]\n",
    "    #prova=prova.iloc[:, :15]\n",
    "    ref=readings[b'Ref']\n",
    "    #ref=ref[0:750500]\n",
    "    #filtering:\n",
    "    prova_rows = range(prova.shape[0])\n",
    "    filt_prova = pd.DataFrame(data = 0, columns=prova.columns, index=prova_rows, dtype = \"float32\")\n",
    "    lowcut = 300\n",
    "    highcut = 3000\n",
    "    fs=10000\n",
    "    order=8\n",
    "    b,a=butter_bandpass(lowcut,highcut,fs,order=order)\n",
    "    filt_ref=filtfilt(b,a,ref)\n",
    "    print('Data Filtering:')\n",
    "    for x in tqdm(range(prova.shape[1])):\n",
    "        filt_prova.values[:,x] = scipy.signal.filtfilt(b, a, prova.values[:,x])\n",
    "    for electrode in prova.columns:\n",
    "        filt_prova[electrode] = filt_prova[electrode] - filt_ref\n",
    "    prova=filt_prova\n",
    "    #detection:\n",
    "    all_ind=[]\n",
    "    print('Spike Detection: ')\n",
    "    for i,electrode in enumerate(tqdm(prova.columns)):\n",
    "        channel=prova[electrode]\n",
    "        #ind=windowed_spike_detection(channel)\n",
    "        ind=this_spike_detection(channel)\n",
    "        all_ind.append(ind)\n",
    "    #spike extraction:\n",
    "    cut_outs=[]\n",
    "    all_new=[]\n",
    "    print('Spike extraction: ')\n",
    "    for i,electrode in enumerate(tqdm(prova.columns)):\n",
    "        ind=all_ind[i]\n",
    "        channel=prova[electrode]\n",
    "        cut_outs1,all_new1=cut_all(ind,channel)\n",
    "        cut_outs.append(cut_outs1)\n",
    "        all_new.append(all_new1)    \n",
    "    # Clustering:\n",
    "    final_data=[]\n",
    "    final_firing=[]\n",
    "    final_firing.append(name_data)\n",
    "    print('Clustering: ')\n",
    "    for channel in (tqdm(range(len(cut_outs)))):\n",
    "        channel_clusters1,final_firing1=clus(cut_outs[channel],all_new[channel],prova.iloc[:,channel])\n",
    "        final_data.append(channel_clusters1)\n",
    "        final_firing.append(final_firing1)\n",
    "    neurons=[]\n",
    "    for channel in final_data:\n",
    "        for neuron in channel:\n",
    "            neurons.append(neuron)\n",
    "    print(len(neurons),' neurons detected and sorted')\n",
    "    adj_neur=[]\n",
    "    counter = 0\n",
    "    max_len=0\n",
    "    for neuron in neurons:\n",
    "        print('counter: ',counter,neuron.shape[0])\n",
    "        if neuron.shape[0]>max_len:\n",
    "            max_len=neuron.shape[0]\n",
    "        counter+=1\n",
    "    for neuron in neurons:\n",
    "        if neuron.shape[0]<max_len:\n",
    "            diff = max_len-neuron.shape[0]\n",
    "            adj_neur.append(np.concatenate((neuron,np.zeros([diff]))))\n",
    "    save_data = 'After'+name_data+'.txt'\n",
    "    #np.savetxt(\"/Users/Gaia_1/Desktop/tesi/Data after SS/%s.txt\" % save_data,adj_neur, delimiter=', ', fmt='%12.8f')\n",
    "    np.savetxt(f\"{output_path}/{save_data}.txt\", adj_neur, delimiter=', ', fmt='%12.8f')\n",
    "\n",
    "    print('saved: ',save_data)\n",
    "    return neurons, final_firing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdf5bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def this_spike_detection(data):\n",
    "    spike_length=30 #3ms (0.003s)\n",
    "    window_length=1000 #0.1 sec (100ms)\n",
    "    neg_data=-(data)\n",
    "    abs_data=abs(data)\n",
    "    i=0\n",
    "    ind=[]\n",
    "    while i < len(data)-window_length:\n",
    "        neg_window=neg_data[i:i+window_length]\n",
    "        abs_window=abs_data[i:i+window_length]\n",
    "        window=data[i:i+window_length]\n",
    "        #coeff=4\n",
    "        #if abso==0:\n",
    "        coeff=3\n",
    "        thresh=coeff*(scipy.stats.median_abs_deviation(window,scale='normal'))\n",
    "        #else:\n",
    "            #coeff=4\n",
    "            #thresh=coeff*(scipy.stats.median_abs_deviation(abs_window,scale='normal'))\n",
    "        ind1, peaks =find_peaks(neg_window, height=thresh,distance=spike_length)\n",
    "        del peaks\n",
    "        last=i\n",
    "        if len(ind1):\n",
    "            last=i+ind1[-1]\n",
    "        ind.extend([index + i for index in ind1])\n",
    "        i=last+spike_length #0.003 s (30ms)\n",
    "    firing_rate=len(ind)*10000/len(data)\n",
    "    print(len(ind), ' spikes detected;  ', 'firing rate: {:.2f}'.format(firing_rate),'Hz')\n",
    "    return ind\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
